{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exZw5qPKE7ry",
        "outputId": "b86c6c93-5957-42d5-99fd-472190475f82",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supabase\n",
            "  Downloading supabase-2.15.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting gotrue<3.0.0,>=2.11.0 (from supabase)\n",
            "  Downloading gotrue-2.12.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx<0.29,>=0.26 in /usr/local/lib/python3.11/dist-packages (from supabase) (0.28.1)\n",
            "Collecting postgrest<1.1,>0.19 (from supabase)\n",
            "  Downloading postgrest-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting realtime<2.5.0,>=2.4.0 (from supabase)\n",
            "  Downloading realtime-2.4.3-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting storage3<0.12,>=0.10 (from supabase)\n",
            "  Downloading storage3-0.11.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting supafunc<0.10,>=0.9 (from supabase)\n",
            "  Downloading supafunc-0.9.4-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.10 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.11.4)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.10.1)\n",
            "Collecting pytest-mock<4.0.0,>=3.14.0 (from gotrue<3.0.0,>=2.11.0->supabase)\n",
            "  Downloading pytest_mock-3.14.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase) (0.16.0)\n",
            "Collecting deprecation<3.0.0,>=2.1.0 (from postgrest<1.1,>0.19->supabase)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting aiohttp<4.0.0,>=3.11.18 (from realtime<2.5.0,>=2.4.0->supabase)\n",
            "  Downloading aiohttp-3.11.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from realtime<2.5.0,>=2.4.0->supabase) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /usr/local/lib/python3.11/dist-packages (from realtime<2.5.0,>=2.4.0->supabase) (4.13.2)\n",
            "Collecting websockets<15,>=11 (from realtime<2.5.0,>=2.4.0->supabase)\n",
            "  Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting strenum<0.5.0,>=0.4.15 (from supafunc<0.10,>=0.9->supabase)\n",
            "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (1.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from deprecation<3.0.0,>=2.1.0->postgrest<1.1,>0.19->supabase) (24.2)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (0.4.0)\n",
            "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.11/dist-packages (from pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (8.3.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.1->realtime<2.5.0,>=2.4.0->supabase) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.3.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (1.5.0)\n",
            "Downloading supabase-2.15.1-py3-none-any.whl (17 kB)\n",
            "Downloading gotrue-2.12.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading postgrest-1.0.1-py3-none-any.whl (22 kB)\n",
            "Downloading realtime-2.4.3-py3-none-any.whl (22 kB)\n",
            "Downloading storage3-0.11.3-py3-none-any.whl (17 kB)\n",
            "Downloading supafunc-0.9.4-py3-none-any.whl (7.8 kB)\n",
            "Downloading aiohttp-3.11.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pytest_mock-3.14.0-py3-none-any.whl (9.9 kB)\n",
            "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
            "Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: strenum, websockets, deprecation, pytest-mock, aiohttp, realtime, supafunc, storage3, postgrest, gotrue, supabase\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.15\n",
            "    Uninstalling aiohttp-3.11.15:\n",
            "      Successfully uninstalled aiohttp-3.11.15\n",
            "Successfully installed aiohttp-3.11.18 deprecation-2.1.0 gotrue-2.12.0 postgrest-1.0.1 pytest-mock-3.14.0 realtime-2.4.3 storage3-0.11.3 strenum-0.4.15 supabase-2.15.1 supafunc-0.9.4 websockets-14.2\n"
          ]
        }
      ],
      "source": [
        "!pip install supabase"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from supabase import create_client, Client\n",
        "\n",
        "url = \"https://ugjwigpcopmtjgylopwf.supabase.co\"\n",
        "key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InVnandpZ3Bjb3BtdGpneWxvcHdmIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDU4MjgxMjIsImV4cCI6MjA2MTQwNDEyMn0.oFcP1wCt1upByqTU8NgD4FpJUdv9I8sG1ECWMX1wz8I\"\n",
        "\n",
        "supabase: Client = create_client(url, key)"
      ],
      "metadata": {
        "id": "Nf-AzKGgFC8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import psutil\n",
        "import pandas as pd\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "# Example: Read all rows from \"cars\" table\n",
        "# Initialize response object\n",
        "response = supabase.table(\"cars_clean\").select(\"*\").range(0, 999).execute()\n",
        "\n",
        "# Set up pagination loop\n",
        "batch_size = 1000\n",
        "offset = 1000  # Start from after the first 1000 rows\n",
        "\n",
        "# Continue fetching in chunks until no more data is left\n",
        "while True:\n",
        "    batch_response = supabase.table(\"cars_clean\").select(\"*\").range(offset, offset + batch_size - 1).execute()\n",
        "    rows = batch_response.data\n",
        "\n",
        "    if not rows:\n",
        "        break\n",
        "\n",
        "    # Add fetched rows to the response.data\n",
        "    response.data.extend(rows)\n",
        "\n",
        "    # Update offset for the next batch\n",
        "    offset += batch_size\n",
        "\n",
        "    print(f\"Fetched {len(response.data)} rows so far...\")\n",
        "\n",
        "# Final result stored in response.data\n",
        "print(f\"✅ Done. Total rows fetched: {len(response.data)}\")\n",
        "\n",
        "#-----------------------Query 1------------------------------\n",
        "def query_most_expensive_car_by_location(data):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create a pandas DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Filter out rows with missing or invalid prices\n",
        "    df = df[df['c_price'].notna() & df['c_price'].apply(lambda x: isinstance(x, (int, float)))]\n",
        "\n",
        "    # Group by location and get the most expensive car\n",
        "    most_expensive_cars = df.loc[df.groupby('c_location')['c_price'].idxmax()]\n",
        "\n",
        "    end_time = time.time()\n",
        "    query_time = end_time - start_time\n",
        "\n",
        "    cpu_percent = psutil.cpu_percent(interval=1)\n",
        "    memory_info = psutil.virtual_memory()\n",
        "    throughput = len(data) / query_time if query_time > 0 else 0\n",
        "\n",
        "    # Create PrettyTable from DataFrame\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"ID\", \"Location\", \"Car Name\", \"Price\"]\n",
        "    for _, row in most_expensive_cars.iterrows():\n",
        "        table.add_row([row[\"id\"], row[\"c_location\"], row[\"c_name\"], row[\"c_price\"]])\n",
        "\n",
        "    print(f\"Total records processed: {len(df)}\")\n",
        "    return table, query_time, cpu_percent, memory_info.percent, throughput  # Memory in MB\n",
        "\n",
        "\n",
        "# Call the function and print the results\n",
        "result_table, query_time, cpu_percent, memory_usage, throughput = query_most_expensive_car_by_location(response.data)\n",
        "print(\"\\nQuery 1: Most Expensive by Location\")\n",
        "print(result_table)\n",
        "\n",
        "print(f\"\\nQuery Performance:\")\n",
        "print(f\"Query Time: {query_time:.4f} seconds\")\n",
        "print(f\"Average CPU Usage: {cpu_percent:.2f}%\")\n",
        "print(f\"Average Memory Usage: {memory_usage:.2f}%\")\n",
        "print(f\"Throughput: {throughput:.2f} records/second\")\n",
        "\n",
        "#-----------------------Query 2------------------------------\n",
        "def query_total_cars_per_year(data):\n",
        "    start_time = time.time()\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    cars_per_year = df['c_year'].value_counts().to_dict()\n",
        "\n",
        "    end_time = time.time()\n",
        "    query_time = end_time - start_time\n",
        "\n",
        "    cpu_percent = psutil.cpu_percent(interval=1)\n",
        "    memory_info = psutil.virtual_memory()\n",
        "    throughput = len(data) / query_time if query_time > 0 else 0\n",
        "\n",
        "    return cars_per_year, query_time, cpu_percent, memory_info.percent, throughput\n",
        "\n",
        "\n",
        "def print_car_counts_table(car_counts, query_time, cpu_percent, memory_percent, throughput):\n",
        "    sorted_counts = sorted(car_counts.items(), key=lambda x: x[0])[:5]\n",
        "\n",
        "    print(\"\\nQuery 2: Total Cars per Year (Top 5)\")\n",
        "    print(\"-\" * 30)\n",
        "    print(\"{:<10} {:<10}\".format(\"Year\", \"Count\"))\n",
        "    print(\"-\" * 30)\n",
        "    for year, count in sorted_counts:\n",
        "      print(\"{:<10} {:<10}\".format(year, count))\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    print(\"\\nQuery Performance:\")\n",
        "    print(f\"  Query Time: {query_time:.4f} seconds\")\n",
        "    print(f\"  Average CPU Usage: {cpu_percent:.2f}%\")\n",
        "    print(f\"  Average Memory Usage: {memory_percent:.2f}%\")\n",
        "    print(f\"  Throughput: {throughput:.2f} records/second\")\n",
        "\n",
        "# Assuming 'response.data' holds the data from the Supabase query\n",
        "car_counts, query_time, cpu_percent, mem_percent, throughput = query_total_cars_per_year(response.data)\n",
        "print_car_counts_table(car_counts, query_time, cpu_percent, mem_percent, throughput)\n",
        "\n",
        "#-----------------------Query 3------------------------------\n",
        "def query_average_price_by_engine_size(data):\n",
        "    start_time = time.time()\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    df['c_engine'] = pd.to_numeric(df['c_engine'], errors='coerce')\n",
        "    df['c_price'] = pd.to_numeric(df['c_price'], errors='coerce')\n",
        "    df.dropna(subset=['c_engine', 'c_price'], inplace=True)\n",
        "\n",
        "    # Define the interval range\n",
        "    interval = 500\n",
        "    min_engine = 0\n",
        "\n",
        "    if df['c_engine'].empty:\n",
        "        max_engine = min_engine\n",
        "    else:\n",
        "        max_engine = df['c_engine'].max()\n",
        "\n",
        "    bins = list(range(min_engine, int(max_engine) + interval + 1, interval))\n",
        "\n",
        "    labels = [f\"{bins[i]}-{bins[i+1]-1}\" for i in range(len(bins)-1)]\n",
        "\n",
        "    if not labels:\n",
        "        if not df.empty:\n",
        "            if max_engine < interval:\n",
        "                single_bin_label = f\"{min_engine}-{interval-1}\"\n",
        "                df['engine_interval'] = single_bin_label\n",
        "                labels = [single_bin_label]\n",
        "            else:\n",
        "                average_prices = {}\n",
        "        else:\n",
        "            average_prices = {}\n",
        "    else:\n",
        "        df['engine_interval'] = pd.cut(df['c_engine'], bins=bins, labels=labels, right=False, include_lowest=True)\n",
        "\n",
        "    if 'engine_interval' in df.columns:\n",
        "        average_prices = df.groupby('engine_interval')['c_price'].mean().dropna().to_dict()\n",
        "    else:\n",
        "        average_prices = {}\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "    query_time = end_time - start_time\n",
        "\n",
        "    try:\n",
        "        cpu_percent = psutil.cpu_percent(interval=0.1)\n",
        "        memory_info = psutil.virtual_memory()\n",
        "        memory_percent = memory_info.percent\n",
        "    except (ImportError, NameError, AttributeError):\n",
        "        cpu_percent = -1.0\n",
        "        memory_percent = -1.0\n",
        "\n",
        "    throughput = len(data) / query_time if query_time > 0 else 0\n",
        "\n",
        "    return average_prices, query_time, cpu_percent, memory_percent, throughput\n",
        "\n",
        "def print_average_prices_table(average_prices, query_time, cpu_percent, memory_percent, throughput):\n",
        "    sorted_prices = sorted(average_prices.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "    print(\"\\nQuery 3: Average Price by Engine Size (Top 5)\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"{:<15} {:<15}\".format(\"Engine Size\", \"Average Price\"))\n",
        "    print(\"-\" * 40)\n",
        "    for engine_size, avg_price in sorted_prices:\n",
        "        print(\"{:<15} {:<15.2f}\".format(engine_size, avg_price))\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    print(\"\\nQuery Performance:\")\n",
        "    print(f\"  Query Time: {query_time:.4f} seconds\")\n",
        "    print(f\"  Average CPU Usage: {cpu_percent:.2f}%\")\n",
        "    print(f\"  Average Memory Usage: {memory_percent:.2f}%\")\n",
        "    print(f\"  Throughput: {throughput:.2f} records/second\")\n",
        "\n",
        "# Assuming 'response.data' holds the data from the Supabase query\n",
        "average_prices, query_time, cpu_percent, mem_percent, throughput = query_average_price_by_engine_size(response.data)\n",
        "print_average_prices_table(average_prices, query_time, cpu_percent, mem_percent, throughput)\n",
        "\n",
        "#-----------------------Query 4------------------------------\n",
        "def query_total_cars_by_location(data):\n",
        "    start_time = time.time()\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    location_counts = df['c_location'].value_counts().to_dict()\n",
        "\n",
        "    end_time = time.time()\n",
        "    query_time = end_time - start_time\n",
        "\n",
        "    cpu_percent = psutil.cpu_percent(interval=1)\n",
        "    memory_info = psutil.virtual_memory()\n",
        "    throughput = len(data) / query_time if query_time > 0 else 0\n",
        "\n",
        "    return location_counts, query_time, cpu_percent, memory_info.percent, throughput\n",
        "\n",
        "def print_total_cars_by_location(location_counts, query_time, cpu_percent, memory_percent, throughput):\n",
        "    print(\"\\nQuery 4: Total Cars by Location\")\n",
        "    print(\"-\" * 30)\n",
        "    print(\"{:<20} {:<10}\".format(\"Location\", \"Count\"))\n",
        "    print(\"-\" * 30)\n",
        "    for location, count in location_counts.items():\n",
        "        print(\"{:<20} {:<10}\".format(location, count))\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    print(\"\\nQuery Performance:\")\n",
        "    print(f\"  Query Time: {query_time:.4f} seconds\")\n",
        "    print(f\"  Average CPU Usage: {cpu_percent:.2f}%\")\n",
        "    print(f\"  Average Memory Usage: {memory_percent:.2f}%\")\n",
        "    print(f\"  Throughput: {throughput:.2f} records/second\")\n",
        "\n",
        "# Assuming 'response.data' holds your data\n",
        "location_counts, query_time, cpu_percent, mem_percent, throughput = query_total_cars_by_location(response.data)\n",
        "print_total_cars_by_location(location_counts, query_time, cpu_percent, mem_percent, throughput)\n",
        "\n",
        "#-----------------------Query 5------------------------------\n",
        "def query_avg_min_mileage_by_condition(data):\n",
        "    start_time = time.time()\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    avg_min_mileage_by_condition = df.groupby('c_condition')['c_mileage_min'].mean().to_dict()\n",
        "\n",
        "    end_time = time.time()\n",
        "    query_time = end_time - start_time\n",
        "\n",
        "    # Calculate CPU and memory usage\n",
        "    cpu_percent = psutil.cpu_percent(interval=1)\n",
        "    memory_info = psutil.virtual_memory()\n",
        "    throughput = len(data) / query_time if query_time > 0 else 0\n",
        "\n",
        "    return avg_min_mileage_by_condition, query_time, cpu_percent, memory_info.percent, throughput\n",
        "\n",
        "\n",
        "def print_avg_min_mileage_by_condition(avg_min_mileage_by_condition, query_time, cpu_percent, memory_percent, throughput):\n",
        "    print(\"\\nQuery 5: Average Minimum Mileage by Condition\")\n",
        "    print(\"-\" * 45)\n",
        "    print(\"{:<20} {:<15}\".format(\"Condition\", \"Avg Min Mileage\"))\n",
        "    print(\"-\" * 45)\n",
        "\n",
        "    for condition, mileage in avg_min_mileage_by_condition.items():\n",
        "        print(\"{:<20} {:<15.2f}\".format(condition, mileage))\n",
        "\n",
        "    print(\"-\" * 45)\n",
        "    print(\"\\nQuery Performance:\")\n",
        "    print(f\"  Query Time: {query_time:.4f} seconds\")\n",
        "    print(f\"  Average CPU Usage: {cpu_percent:.2f}%\")\n",
        "    print(f\"  Average Memory Usage: {memory_percent:.2f}%\")\n",
        "    print(f\"  Throughput: {throughput:.2f} records/second\")\n",
        "\n",
        "# Execute the query and print results\n",
        "min_mileage_result, query_time, cpu_percent, mem_percent, throughput = query_avg_min_mileage_by_condition(response.data)\n",
        "print_avg_min_mileage_by_condition(min_mileage_result, query_time, cpu_percent, mem_percent, throughput)"
      ],
      "metadata": {
        "id": "Wg8a5ntYFCFL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "03b3af1a-9f5f-483a-fdb2-d7079ba28e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 2000 rows so far...\n",
            "Fetched 3000 rows so far...\n",
            "Fetched 4000 rows so far...\n",
            "Fetched 5000 rows so far...\n",
            "Fetched 6000 rows so far...\n",
            "Fetched 7000 rows so far...\n",
            "Fetched 8000 rows so far...\n",
            "Fetched 9000 rows so far...\n",
            "Fetched 10000 rows so far...\n",
            "Fetched 11000 rows so far...\n",
            "Fetched 12000 rows so far...\n",
            "Fetched 13000 rows so far...\n",
            "Fetched 14000 rows so far...\n",
            "Fetched 15000 rows so far...\n",
            "Fetched 16000 rows so far...\n",
            "Fetched 17000 rows so far...\n",
            "Fetched 18000 rows so far...\n",
            "Fetched 19000 rows so far...\n",
            "Fetched 20000 rows so far...\n",
            "Fetched 21000 rows so far...\n",
            "Fetched 22000 rows so far...\n",
            "Fetched 23000 rows so far...\n",
            "Fetched 24000 rows so far...\n",
            "Fetched 25000 rows so far...\n",
            "Fetched 26000 rows so far...\n",
            "Fetched 27000 rows so far...\n",
            "Fetched 28000 rows so far...\n",
            "Fetched 29000 rows so far...\n",
            "Fetched 30000 rows so far...\n",
            "Fetched 31000 rows so far...\n",
            "Fetched 32000 rows so far...\n",
            "Fetched 33000 rows so far...\n",
            "Fetched 34000 rows so far...\n",
            "Fetched 35000 rows so far...\n",
            "Fetched 36000 rows so far...\n",
            "Fetched 37000 rows so far...\n",
            "Fetched 38000 rows so far...\n",
            "Fetched 39000 rows so far...\n",
            "Fetched 40000 rows so far...\n",
            "Fetched 41000 rows so far...\n",
            "Fetched 42000 rows so far...\n",
            "Fetched 43000 rows so far...\n",
            "Fetched 44000 rows so far...\n",
            "Fetched 45000 rows so far...\n",
            "Fetched 46000 rows so far...\n",
            "Fetched 47000 rows so far...\n",
            "Fetched 48000 rows so far...\n",
            "Fetched 49000 rows so far...\n",
            "Fetched 50000 rows so far...\n",
            "Fetched 51000 rows so far...\n",
            "Fetched 52000 rows so far...\n",
            "Fetched 53000 rows so far...\n",
            "Fetched 54000 rows so far...\n",
            "Fetched 55000 rows so far...\n",
            "Fetched 56000 rows so far...\n",
            "Fetched 57000 rows so far...\n",
            "Fetched 58000 rows so far...\n",
            "Fetched 59000 rows so far...\n",
            "Fetched 60000 rows so far...\n",
            "Fetched 61000 rows so far...\n",
            "Fetched 62000 rows so far...\n",
            "Fetched 63000 rows so far...\n",
            "Fetched 64000 rows so far...\n",
            "Fetched 65000 rows so far...\n",
            "Fetched 66000 rows so far...\n",
            "Fetched 67000 rows so far...\n",
            "Fetched 68000 rows so far...\n",
            "Fetched 69000 rows so far...\n",
            "Fetched 70000 rows so far...\n",
            "Fetched 71000 rows so far...\n",
            "Fetched 72000 rows so far...\n",
            "Fetched 73000 rows so far...\n",
            "Fetched 74000 rows so far...\n",
            "Fetched 75000 rows so far...\n",
            "Fetched 76000 rows so far...\n",
            "Fetched 77000 rows so far...\n",
            "Fetched 78000 rows so far...\n",
            "Fetched 79000 rows so far...\n",
            "Fetched 80000 rows so far...\n",
            "Fetched 81000 rows so far...\n",
            "Fetched 82000 rows so far...\n",
            "Fetched 83000 rows so far...\n",
            "Fetched 84000 rows so far...\n",
            "Fetched 85000 rows so far...\n",
            "Fetched 86000 rows so far...\n",
            "Fetched 87000 rows so far...\n",
            "Fetched 88000 rows so far...\n",
            "Fetched 89000 rows so far...\n",
            "Fetched 90000 rows so far...\n",
            "Fetched 91000 rows so far...\n",
            "Fetched 92000 rows so far...\n",
            "Fetched 93000 rows so far...\n",
            "Fetched 94000 rows so far...\n",
            "Fetched 95000 rows so far...\n",
            "Fetched 96000 rows so far...\n",
            "Fetched 97000 rows so far...\n",
            "Fetched 98000 rows so far...\n",
            "Fetched 99000 rows so far...\n",
            "Fetched 100000 rows so far...\n",
            "Fetched 101000 rows so far...\n",
            "Fetched 102000 rows so far...\n",
            "Fetched 103000 rows so far...\n",
            "Fetched 104000 rows so far...\n",
            "Fetched 105000 rows so far...\n",
            "Fetched 106000 rows so far...\n",
            "Fetched 107000 rows so far...\n",
            "Fetched 108000 rows so far...\n",
            "Fetched 109000 rows so far...\n",
            "Fetched 110000 rows so far...\n",
            "Fetched 111000 rows so far...\n",
            "Fetched 112000 rows so far...\n",
            "Fetched 113000 rows so far...\n",
            "Fetched 114000 rows so far...\n",
            "Fetched 115000 rows so far...\n",
            "Fetched 115001 rows so far...\n",
            "✅ Done. Total rows fetched: 115001\n",
            "Total records processed: 115001\n",
            "\n",
            "Query 1: Most Expensive by Location\n",
            "+--------+-----------------+-----------------------------------------------+---------+\n",
            "|   ID   |     Location    |                    Car Name                   |  Price  |\n",
            "+--------+-----------------+-----------------------------------------------+---------+\n",
            "| 88400  |      Johor      | Ferrari SF90 STRADALE 3.9 *1000hp Ready Stock | 4180000 |\n",
            "|  4697  |      Kedah      | Mclaren 720S 765LT SPIDER 1 OF 765 READY UNIT | 1880000 |\n",
            "| 117166 |     Kelantan    |  Land Rover RANGE ROVER 3.0 Big Spec P400 HST |  548000 |\n",
            "| 86014  |   Kuala Lumpur  |       Rolls Royce PHANTOM  6.75 V12 EWB       | 4900000 |\n",
            "| 118043 |      Labuan     |  Hyundai GRAND STAREX EXECUTIVE PLUS 2.5L (A) |  125000 |\n",
            "| 92133  |      Melaka     |       Porsche 911 3.8 CARRERA S 991 (A)       |  489000 |\n",
            "| 88258  | Negeri Sembilan |         Ferrari F12 BERLINETTA 6.3 (A)        | 1010000 |\n",
            "| 87864  |      Pahang     |  Mercedes Benz S63 4.0 AMG COUPE V8 BiTurbo S |  707000 |\n",
            "| 111306 |      Penang     | Rolls Royce CULLINAN 6.75 V12 (A) BLACK BADGE | 3498888 |\n",
            "| 90583  |      Perak      |         Porsche 992 3.0 CARRERA S (A)         |  828000 |\n",
            "| 86503  |      Perlis     |   Bmw 340i xDRIVE M SPORT PRO M 3.0 MY19 G20  |  343800 |\n",
            "| 111030 |    Putrajaya    | Mercedes Benz G350 D 3.0 AMG (A) S/ROOF UNREG |  568000 |\n",
            "| 114269 |      Sabah      |          Lexus LX500d 3.3 F SPORT (A)         |  889000 |\n",
            "| 90503  |     Sarawak     |   Ferrari 488 Pista 3.9 V8 Twin-turbocharged  | 2660000 |\n",
            "|  6984  |     Selangor    |       Ferrari 812 Competizione Rosso TRS      | 8988000 |\n",
            "|  2327  |    Terengganu   |          Honda CIVIC 1.8 S i-VTEC (A)         | 2700000 |\n",
            "+--------+-----------------+-----------------------------------------------+---------+\n",
            "\n",
            "Query Performance:\n",
            "Query Time: 0.4231 seconds\n",
            "Average CPU Usage: 2.50%\n",
            "Average Memory Usage: 9.60%\n",
            "Throughput: 271804.04 records/second\n",
            "\n",
            "Query 2: Total Cars per Year (Top 5)\n",
            "------------------------------\n",
            "Year       Count     \n",
            "------------------------------\n",
            "1995       1349      \n",
            "1996       374       \n",
            "1997       493       \n",
            "1998       188       \n",
            "1999       318       \n",
            "------------------------------\n",
            "\n",
            "Query Performance:\n",
            "  Query Time: 0.3137 seconds\n",
            "  Average CPU Usage: 3.00%\n",
            "  Average Memory Usage: 9.60%\n",
            "  Throughput: 366609.45 records/second\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-103337c572da>:150: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  average_prices = df.groupby('engine_interval')['c_price'].mean().dropna().to_dict()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query 3: Average Price by Engine Size (Top 5)\n",
            "----------------------------------------\n",
            "Engine Size     Average Price  \n",
            "----------------------------------------\n",
            "6500-6999       2350916.15     \n",
            "6000-6499       2230549.17     \n",
            "99500-99999     1184000.00     \n",
            "3500-3999       924417.12      \n",
            "5000-5499       825514.12      \n",
            "----------------------------------------\n",
            "\n",
            "Query Performance:\n",
            "  Query Time: 0.3443 seconds\n",
            "  Average CPU Usage: 15.00%\n",
            "  Average Memory Usage: 9.60%\n",
            "  Throughput: 333993.10 records/second\n",
            "\n",
            "Query 4: Total Cars by Location\n",
            "------------------------------\n",
            "Location             Count     \n",
            "------------------------------\n",
            "Selangor             36908     \n",
            "Kuala Lumpur         31232     \n",
            "Johor                18904     \n",
            "Penang               6312      \n",
            "Perak                5107      \n",
            "Sabah                3440      \n",
            "Kedah                3245      \n",
            "Sarawak              2268      \n",
            "Melaka               1647      \n",
            "Negeri Sembilan      1552      \n",
            "Pahang               1509      \n",
            "Kelantan             1441      \n",
            "Terengganu           1063      \n",
            "Putrajaya            197       \n",
            "Perlis               143       \n",
            "Labuan               33        \n",
            "------------------------------\n",
            "\n",
            "Query Performance:\n",
            "  Query Time: 0.3294 seconds\n",
            "  Average CPU Usage: 2.50%\n",
            "  Average Memory Usage: 9.60%\n",
            "  Throughput: 349147.85 records/second\n",
            "\n",
            "Query 5: Average Minimum Mileage by Condition\n",
            "---------------------------------------------\n",
            "Condition            Avg Min Mileage\n",
            "---------------------------------------------\n",
            "New                  3906.98        \n",
            "Recon                21719.84       \n",
            "Used                 99596.60       \n",
            "---------------------------------------------\n",
            "\n",
            "Query Performance:\n",
            "  Query Time: 0.5381 seconds\n",
            "  Average CPU Usage: 54.80%\n",
            "  Average Memory Usage: 9.70%\n",
            "  Throughput: 213734.58 records/second\n"
          ]
        }
      ]
    }
  ]
}