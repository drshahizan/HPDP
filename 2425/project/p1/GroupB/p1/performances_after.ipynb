{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Polars"
      ],
      "metadata": {
        "id": "lcEKuI3EKmLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install polars psutil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLQdOLkbKvxE",
        "outputId": "e061080e-0c01-4ca3-97c2-e17af68b0c46"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (5.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "import json\n",
        "\n",
        "def run_polars_optimization():\n",
        "    start_time = time.time()\n",
        "    process = psutil.Process(os.getpid())\n",
        "    cpu_start = psutil.cpu_percent(interval=None)\n",
        "    memory_start = process.memory_info().rss / (1024 * 1024)  # MB\n",
        "\n",
        "    # Read CSV with error handling for problematic columns\n",
        "    df = pl.read_csv(\n",
        "        \"cleaned_data.csv\",\n",
        "        try_parse_dates=True,\n",
        "        ignore_errors=True,  # Skip rows with parsing errors\n",
        "        null_values=[\"-\", \"NA\", \"N/A\", \"\"]  # Treat these as null values\n",
        "    )\n",
        "\n",
        "    # Alternatively, specify dtypes for problematic columns\n",
        "    # df = pl.read_csv(\n",
        "    #     \"cleaned_data.csv\",\n",
        "    #     dtypes={\n",
        "    #         \"seating capacity\": pl.Utf8  # Read as string first\n",
        "    #     }\n",
        "    # )\n",
        "\n",
        "    # If needed, you can then clean the problematic column\n",
        "    # df = df.with_columns(\n",
        "    #     pl.col(\"seating capacity\")\n",
        "    #     .str.extract(r\"(\\d+)\")  # Extract numbers\n",
        "    #     .cast(pl.Int64)  # Convert to integer\n",
        "    # )\n",
        "\n",
        "    row_count = df.shape[0]\n",
        "    mean_price = df[\"price (myr)\"].mean()\n",
        "    mean_mileage = df[\"mileage\"].mean()\n",
        "\n",
        "    # Handle mode safely in case all values are null\n",
        "    region_mode = df[\"region\"].mode()\n",
        "    most_common_region = region_mode[0] if len(region_mode) > 0 else \"N/A\"\n",
        "\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    cpu_end = psutil.cpu_percent(interval=None)\n",
        "    memory_end = process.memory_info().rss / (1024 * 1024)  # MB\n",
        "\n",
        "    metrics = {\n",
        "        \"Optimization Stage\": \"Polars Optimization\",\n",
        "        \"Total Rows\": row_count,\n",
        "        \"Total Processing Time (seconds)\": execution_time,\n",
        "        \"CPU Usage (%)\": cpu_end - cpu_start,\n",
        "        \"Memory Usage (MB)\": memory_end - memory_start,\n",
        "        \"Throughput (records/second)\": row_count / execution_time,\n",
        "        \"Data Processed (rows)\": row_count,\n",
        "        \"Time Taken (seconds)\": execution_time,\n",
        "        \"Records per second\": row_count / execution_time\n",
        "    }\n",
        "\n",
        "    print(\"\\n‚úÖ Polars Optimization Complete\")\n",
        "    print(f\"üìÑ Total Rows: {row_count}\")\n",
        "    print(f\"üïí Total Processing Time: {execution_time:.2f} seconds\")\n",
        "    print(f\"üß† CPU Usage: {cpu_end - cpu_start:.2f}%\")\n",
        "    print(f\"üíæ Memory Usage: {memory_end - memory_start:.2f} MB\")\n",
        "    print(f\"‚ö° Throughput: {row_count / execution_time:.2f} records/second\")\n",
        "    print(f\"üí∏ Mean Price (MYR): RM {mean_price:.2f}\")\n",
        "    print(f\"üõ£Ô∏è Mean Mileage: {mean_mileage:.2f}km\")\n",
        "    print(f\"üìç Most Common Region: {most_common_region}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    metrics = run_polars_optimization()\n",
        "    # Save metrics to a temporary JSON file\n",
        "    with open(\"polars_metrics.json\", \"w\") as f:\n",
        "        json.dump(metrics, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qrTGRes9r-O",
        "outputId": "e37440c2-f68f-4f6c-854c-874681c2c6f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Polars Optimization Complete\n",
            "üìÑ Total Rows: 175545\n",
            "üïí Total Processing Time: 0.61 seconds\n",
            "üß† CPU Usage: 14.80%\n",
            "üíæ Memory Usage: 129.63 MB\n",
            "‚ö° Throughput: 289688.39 records/second\n",
            "üí∏ Mean Price (MYR): RM 208327.84\n",
            "üõ£Ô∏è Mean Mileage: 56206.03km\n",
            "üìç Most Common Region: selangor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas"
      ],
      "metadata": {
        "id": "A6P-peUpKzFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import psutil\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "def run_pandas_optimization():\n",
        "    # ========== Warm-up Run ==========\n",
        "    _ = pd.read_csv('cleaned_data.csv').head(100)  # Initialize libraries\n",
        "\n",
        "    # ========== Start Performance Tracking ==========\n",
        "    start_time = time.time()\n",
        "    process = psutil.Process(os.getpid())\n",
        "\n",
        "    # Stable CPU measurement\n",
        "    cpu_readings = [psutil.cpu_percent(interval=0.1) for _ in range(3)]\n",
        "    cpu_start = sum(cpu_readings) / len(cpu_readings)\n",
        "\n",
        "    memory_start = process.memory_info().rss / (1024 * 1024)  # in MB\n",
        "\n",
        "    # ========== Read and Process Data ==========\n",
        "    df = pd.read_csv('cleaned_data.csv', encoding='utf-8')\n",
        "\n",
        "    # Data cleaning\n",
        "    df.dropna(subset=['price (myr)', 'mileage', 'region'], inplace=True)\n",
        "    df['price (myr)'] = pd.to_numeric(df['price (myr)'], errors='coerce')\n",
        "    df['mileage'] = pd.to_numeric(df['mileage'], errors='coerce')\n",
        "    df = df.dropna(subset=['price (myr)', 'mileage'])\n",
        "\n",
        "    # ========== Compute Metrics ==========\n",
        "    total_rows = len(df)\n",
        "    mean_price = df['price (myr)'].mean()\n",
        "    mean_mileage = df['mileage'].mean()\n",
        "    most_common_region = df['region'].mode()[0] if not df['region'].empty else \"N/A\"\n",
        "\n",
        "    # ========== End Performance Tracking ==========\n",
        "    end_time = time.time()\n",
        "    cpu_end = psutil.cpu_percent(interval=0.1)\n",
        "    memory_end = process.memory_info().rss / (1024 * 1024)\n",
        "    execution_time = end_time - start_time\n",
        "\n",
        "    # ========== Prepare Results ==========\n",
        "    metrics = {\n",
        "        \"Optimization Stage\": \"Pandas Optimization\",\n",
        "            \"Total Rows\": total_rows,\n",
        "            \"Total Processing Time (seconds)\": execution_time,\n",
        "            \"CPU Usage (%)\": cpu_end - cpu_start,\n",
        "            \"Memory Usage (MB)\": memory_end - memory_start,\n",
        "            \"Throughput (records/second)\": total_rows / execution_time,\n",
        "            \"Data Processed (rows)\": total_rows,\n",
        "            \"Time Taken (seconds)\": execution_time,\n",
        "            \"Records per second\": total_rows / execution_time\n",
        "    }\n",
        "\n",
        "    # ========== Print Results ==========\n",
        "    print(\"\\nüêç Pandas Optimization Complete\")\n",
        "    print(f\"üìÑ Total Rows: {total_rows}\")\n",
        "    print(f\"üïí Total Processing Time: {execution_time:.2f} seconds\")\n",
        "    print(f\"üß† CPU Usage: {cpu_end - cpu_start:.2f}%\")\n",
        "    print(f\"üíæ Memory Usage: {memory_end - memory_start:.2f} MB\")\n",
        "    print(f\"‚ö° Throughput: {total_rows / execution_time:.2f} records/second\")\n",
        "    print(f\"üí∏ Mean Price (MYR): RM {mean_price:.2f}\")\n",
        "    print(f\"üõ£Ô∏è Mean Mileage: {mean_mileage:.2f} km\")\n",
        "    print(f\"üìç Most Common Region: {most_common_region}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    metrics = run_pandas_optimization()\n",
        "    with open(\"pandas_metrics.json\", \"w\") as f:\n",
        "        json.dump(metrics, f)\n",
        "    print(\"\\n‚úÖ Metrics saved to pandas_metrics.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmBPFOyFK0ND",
        "outputId": "c2aa9e56-d482-402b-fce3-c0c8da7673bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üêç Pandas Optimization Complete\n",
            "üìÑ Total Rows: 175545\n",
            "üïí Total Processing Time: 3.44 seconds\n",
            "üß† CPU Usage: 3.60%\n",
            "üíæ Memory Usage: 125.80 MB\n",
            "‚ö° Throughput: 51003.49 records/second\n",
            "üí∏ Mean Price (MYR): RM 208327.84\n",
            "üõ£Ô∏è Mean Mileage: 56206.03 km\n",
            "üìç Most Common Region: selangor\n",
            "\n",
            "‚úÖ Metrics saved to pandas_metrics.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DuckDB"
      ],
      "metadata": {
        "id": "0dR78tcUK2LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import time\n",
        "import os\n",
        "import psutil\n",
        "import json\n",
        "\n",
        "def run_duckdb_optimization():\n",
        "    # ========== Start Performance Tracking ==========\n",
        "    start_time = time.time()\n",
        "    process = psutil.Process(os.getpid())\n",
        "    cpu_start = psutil.cpu_percent(interval=None)\n",
        "    memory_start = process.memory_info().rss / (1024 * 1024)  # in MB\n",
        "\n",
        "    # ========== Connect to DuckDB ==========\n",
        "    conn = duckdb.connect(database=':memory:')\n",
        "\n",
        "    try:\n",
        "        # ========== Execute Optimized Query ==========\n",
        "        result = conn.execute(\"\"\"\n",
        "            WITH car_data AS (\n",
        "                SELECT\n",
        "                    TRY_CAST(\"price (myr)\" AS DOUBLE) AS price,\n",
        "                    TRY_CAST(mileage AS DOUBLE) AS mileage,\n",
        "                    TRIM(region) AS region\n",
        "                FROM read_csv('cleaned_data.csv',\n",
        "                             header=true,\n",
        "                             auto_detect=true,\n",
        "                             ignore_errors=true)\n",
        "                WHERE \"price (myr)\" IS NOT NULL\n",
        "                  AND mileage IS NOT NULL\n",
        "                  AND region IS NOT NULL\n",
        "            )\n",
        "            SELECT\n",
        "                COUNT(*) AS total_rows,\n",
        "                AVG(price) AS mean_price,\n",
        "                AVG(mileage) AS mean_mileage,\n",
        "                FIRST(region ORDER BY region_count DESC) AS most_common_region\n",
        "            FROM (\n",
        "                SELECT\n",
        "                    *,\n",
        "                    COUNT(*) OVER (PARTITION BY region) AS region_count\n",
        "                FROM car_data\n",
        "            )\n",
        "        \"\"\").fetchone()\n",
        "\n",
        "        total_rows = result[0]\n",
        "        mean_price = result[1]\n",
        "        mean_mileage = result[2]\n",
        "        most_common_region = result[3]\n",
        "\n",
        "        # ========== End Performance Tracking ==========\n",
        "        end_time = time.time()\n",
        "        cpu_end = psutil.cpu_percent(interval=None)\n",
        "        memory_end = process.memory_info().rss / (1024 * 1024)  # in MB\n",
        "        execution_time = end_time - start_time\n",
        "\n",
        "        # Prepare metrics dictionary\n",
        "        metrics = {\n",
        "            \"Optimization Stage\": \"DuckDB Optimization\",\n",
        "            \"Total Rows\": total_rows,\n",
        "            \"Total Processing Time (seconds)\": execution_time,\n",
        "            \"CPU Usage (%)\": cpu_end - cpu_start,\n",
        "            \"Memory Usage (MB)\": memory_end - memory_start,\n",
        "            \"Throughput (records/second)\": total_rows / execution_time,\n",
        "            \"Data Processed (rows)\": total_rows,\n",
        "            \"Time Taken (seconds)\": execution_time,\n",
        "            \"Records per second\": total_rows / execution_time\n",
        "        }\n",
        "\n",
        "        # ========== Print Metrics ==========\n",
        "        print(\"\\nüöÄ DuckDB (FireDucks) - After Optimization\")\n",
        "        print(f\"üìÑ Total Rows: {total_rows}\")\n",
        "        print(f\"üïí Total Processing Time: {execution_time:.2f} seconds\")\n",
        "        print(f\"üß† CPU Usage: {cpu_end - cpu_start:.2f}%\")\n",
        "        print(f\"üíæ Memory Usage: {memory_end - memory_start:.2f} MB\")\n",
        "        print(f\"‚ö° Throughput: {total_rows / execution_time:.2f} records/second\")\n",
        "        print(f\"üí∏ Mean Price (MYR): RM {mean_price:.2f}\")\n",
        "        print(f\"üõ£Ô∏è Mean Mileage: {mean_mileage:.2f} km\")\n",
        "        print(f\"üìç Most Common Region: {most_common_region}\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    metrics = run_duckdb_optimization()\n",
        "    # Save metrics to a temporary JSON file\n",
        "    with open(\"duckdb_metrics.json\", \"w\") as f:\n",
        "        json.dump(metrics, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3WlTGSSK3l6",
        "outputId": "2dfa4998-cc94-4786-d2c3-b4193132e597"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ DuckDB (FireDucks) - After Optimization\n",
            "üìÑ Total Rows: 175545\n",
            "üïí Total Processing Time: 0.43 seconds\n",
            "üß† CPU Usage: 46.20%\n",
            "üíæ Memory Usage: 81.64 MB\n",
            "‚ö° Throughput: 406446.43 records/second\n",
            "üí∏ Mean Price (MYR): RM 208327.84\n",
            "üõ£Ô∏è Mean Mileage: 56206.03 km\n",
            "üìç Most Common Region: selangor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def load_and_clean_metrics():\n",
        "    # Initialize empty DataFrame with the correct columns\n",
        "    columns = [\n",
        "        'Optimization Stage',\n",
        "        'Total Rows',\n",
        "        'Total Processing Time (seconds)',\n",
        "        'CPU Usage (%)',\n",
        "        'Memory Usage (MB)',\n",
        "        'Throughput (records/second)',\n",
        "        'Data Processed (rows)',\n",
        "        'Time Taken (seconds)',\n",
        "        'Records per second'\n",
        "    ]\n",
        "    df = pd.DataFrame(columns=columns)\n",
        "\n",
        "    # Load metrics from JSON files if they exist\n",
        "    json_files = {\n",
        "        'Polars' : 'polars_metrics.json',\n",
        "        'Pandas': 'pandas_metrics.json',\n",
        "        'DuckDB': 'duckdb_metrics.json'\n",
        "    }\n",
        "\n",
        "    for stage, file in json_files.items():\n",
        "        if Path(file).exists():\n",
        "            with open(file) as f:\n",
        "                metrics = json.load(f)\n",
        "                # Convert to DataFrame and append\n",
        "                temp_df = pd.DataFrame([metrics])\n",
        "                df = pd.concat([df, temp_df], ignore_index=True)\n",
        "\n",
        "    if not df.empty:\n",
        "        # Round all numeric columns to 2 decimals\n",
        "        numeric_cols = df.select_dtypes(include=['float64']).columns\n",
        "        df[numeric_cols] = df[numeric_cols].round(2)\n",
        "\n",
        "        # Fix negative memory values (take absolute value)\n",
        "        df['Memory Usage (MB)'] = df['Memory Usage (MB)'].abs()\n",
        "\n",
        "        # Format throughput and records per second without commas\n",
        "        df['Throughput (records/second)'] = df['Throughput (records/second)'].apply(lambda x: f\"{float(x):.2f}\")\n",
        "        df['Records per second'] = df['Records per second'].apply(lambda x: f\"{float(x):.2f}\")\n",
        "\n",
        "        # Save cleaned data\n",
        "        df.to_csv(\"performance_after.csv\", index=False)\n",
        "        print(\"Successfully saved cleaned metrics to performance_after.csv\")\n",
        "        return df\n",
        "    else:\n",
        "        print(\"No JSON metrics files found (pandas_metrics.json, duckdb_metrics.json)\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    result_df = load_and_clean_metrics()\n",
        "    if result_df is not None:\n",
        "        print(\"\\nCleaned Performance Metrics:\")\n",
        "        print(result_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFwkg6edLowl",
        "outputId": "cc3859aa-cc6e-4395-dc87-7478fb830a4e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved cleaned metrics to performance_after.csv\n",
            "\n",
            "Cleaned Performance Metrics:\n",
            "    Optimization Stage Total Rows  Total Processing Time (seconds)  \\\n",
            "0  Polars Optimization     175545                             0.61   \n",
            "1  Pandas Optimization     175545                             3.44   \n",
            "2  DuckDB Optimization     175545                             0.43   \n",
            "\n",
            "   CPU Usage (%)  Memory Usage (MB) Throughput (records/second)  \\\n",
            "0           14.8             129.63                   289688.39   \n",
            "1            3.6             125.80                    51003.49   \n",
            "2           46.2              81.64                   406446.43   \n",
            "\n",
            "  Data Processed (rows)  Time Taken (seconds) Records per second  \n",
            "0                175545                  0.61          289688.39  \n",
            "1                175545                  3.44           51003.49  \n",
            "2                175545                  0.43          406446.43  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-f6e9277017df>:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, temp_df], ignore_index=True)\n"
          ]
        }
      ]
    }
  ]
}