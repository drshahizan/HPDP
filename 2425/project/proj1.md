<a href="https://github.com/drshahizan/HPDP/stargazers"><img src="https://img.shields.io/github/stars/drshahizan/HPDP" alt="Stars Badge"/></a>
<a href="https://github.com/drshahizan/HPDP/network/members"><img src="https://img.shields.io/github/forks/drshahizan/HPDP" alt="Forks Badge"/></a>
<a href="https://github.com/drshahizan/HPDP/pulls"><img src="https://img.shields.io/github/issues-pr/drshahizan/HPDP" alt="Pull Requests Badge"/></a>
<a href="https://github.com/drshahizan/HPDP/issues"><img src="https://img.shields.io/github/issues/drshahizan/HPDP" alt="Issues Badge"/></a>
<a href="https://github.com/drshahizan/HPDP/graphs/contributors"><img alt="GitHub contributors" src="https://img.shields.io/github/contributors/drshahizan/HPDP?color=2b9348"></a>
![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fdrshahizan%2FHPDP&labelColor=%23d9e3f0&countColor=%23697689&style=flat)

# üìÑ Project 1: Optimizing High-Performance Data Processing for Large-Scale Web Crawlers

## Project Synopsis
This project introduces students to real-world applications of high-performance computing (HPC) in large-scale web data processing. Students will work collaboratively in diverse teams to design, develop, and optimize a web crawler capable of extracting a minimum of **100,000 structured records** from a **Malaysian website**. Emphasis is placed on the practical implementation of **multithreading, multiprocessing, and distributed processing** techniques to improve the efficiency and scalability of the system. 

Through hands-on experience, students will explore data collection, cleaning, transformation, and storage, while addressing technical challenges such as crawl delays, ethical scraping, and performance bottlenecks. The project culminates with a comprehensive performance evaluation comparing pre- and post-optimization results. Deliverables include a final technical report, source code, cleaned dataset, performance analysis, and a group presentation. 

This project aims to develop students' technical skills in high-performance computing, critical thinking in system optimization, and collaboration in diverse teams‚Äîkey competencies for data science professionals.

üìä **Weightage**: 15% of total course assessment  
üïì Project Duration: 4 Weeks
üìÖ **Submission Deadline**: **Friday, 16 May 2025**  
üì§ **Submission Format**: All final documents must be uploaded via e-learning and github  
üë• **Assignment Type**: **4 students per group (Max)**. 
> üìå Each group must include students from **different genders, races, or backgrounds** to encourage diversity and collaboration across cultures and perspectives.

## üß† **What Is This Project About?**

This project gives you the chance to **design, build, and optimize a high-performance data processing system** that collects information from the internet. You will create a **web crawler** to extract data from a **Malaysian website** and then process this data using **advanced computing techniques** to make the process faster and more efficient.

### üí° What makes this ‚Äúhigh-performance‚Äù?
You are expected to use computing methods that improve performance, such as:
- **Multithreading** ‚Äì running multiple tasks at the same time
- **Multiprocessing** ‚Äì using multiple CPU cores for different parts of the program
- **Distributed computing** ‚Äì spreading the task across several machines or processes (e.g., using Spark)

You will also **compare the performance before and after optimization**, and show what makes your design better.

## üéØ **Project Goals**

By the end of this project, you will be able to:
1. Build a **web crawler** to extract large amounts of data from a real-world Malaysian website.
2. Process and clean the data to prepare it for analysis or storage.
3. Apply **high-performance computing techniques** to improve the speed and efficiency of your solution.
4. Work as part of a **diverse, collaborative team**.
5. Evaluate your system‚Äôs performance and explain how it was improved.
6. Present your work professionally through reports and presentations.

## üìå Project Requirements

### ‚úÖ Technical Requirements:
- Crawl and collect **at least 100,000 records** from a single Malaysian website.
- Store the data in **CSV, JSON, or database**.
- Clean and process the data (e.g., remove duplicates, standardize fields).
- Apply at least **two optimization methods** to make your system faster and more efficient.
- Include performance comparison **(before vs after optimization)**
  
### ‚úÖ Deliverables
| No. | Item | Description |
|-----|------|-------------|
| 1 | **Final Report** | A complete document with background, methods, results, and discussion. Must be uploaded to Turnitin (PDF). |
| 2 | **Source Code** | Your crawler and processing pipeline, well organized and commented. Submit as GitHub link or ZIP file. |
| 3 | **Clean Dataset** | At least 100,000 valid, structured records in CSV/JSON/database. |
| 4 | **Performance Comparison** | Include charts or tables comparing performance before and after optimization. |
| 5 | **Presentation Slides** | 10-minute group presentation explaining your project. |

## üîó Quick Access to Supporting Resources

- üåê [Suggested Malaysian Websites for Crawling](p1_web.md)  
- üß≠ [Step-by-Step Project Guide](p1_step.md)  
- üßæ [Assessment Rubric](p1_rubric.md)  
- üîó [Recommended Repositories & Tools](p1_tools.md)  
- ‚úÖ [Checklist & Timeline Tracker](p1_checklist.md)  
- üìÑ [Sample Report Structure](p1_report.md)  
- üìÅ [GitHub Folder Submission Template](p1_github.md)

## Submission

1. Web scraping
   
| Team | Website | Tools |  Open in GitHub |
| ----- | ----- | ------ | ------ | 
| Sample | [StudyMalaysia.com](https://www.studymalaysia.com) | Beautiful soup| [![Open in GitHub](https://img.shields.io/static/v1?label=&message=Open%20in%20GitHub&labelColor=grey&color=blue&logo=github)](p1/sample/A1) |
|       |        |        |        |
|       |        |        |        |
|       |        |        |        |
| Group D | mudah.my(rent-property) | Beautiful Soup + Request| [![Open in GitHub](https://img.shields.io/static/v1?label=&message=Open%20in%20GitHub&labelColor=grey&color=blue&logo=github)](p1/GroupD)|
|       |        |        |        |
|       |        |        |        |
| Group G | [NST](https://www.nst.com.my/ ) |   Playwright  |  [![Open in GitHub](https://img.shields.io/static/v1?label=&message=Open%20in%20GitHub&labelColor=grey&color=blue&logo=github)](p1/GroupG)      |

2. Performance Comparison

| Team | Library 1 | Library 2 | Library 3 | Dataset |  Open in GitHub |
| ----- | ----- | ------ | ------ |  ------ | :------: | 
| Sample1 | Pandas | Dask | Koalas | Air Flight Analysis | [![Open in GitHub](https://img.shields.io/static/v1?label=&message=Open%20in%20GitHub&labelColor=grey&color=blue&logo=github)](p1/sample/A2) |
|       |          |           |           |         |                  |
|       |          |           |           |         |                  |
|       |          |           |           |         |                  |
|       |          |           |           |         |                  |
|       |          |           |           |         |                  |
|       |          |           |           |         |                  |
| Group G | Playwright | BeautifulSoup |  Pandas |  Sports News Analysis    | [![Open in GitHub](https://img.shields.io/static/v1?label=&message=Open%20in%20GitHub&labelColor=grey&color=blue&logo=github)](p1/GroupG)  |

## Contribution üõ†Ô∏è
Please create an [Issue](https://github.com/drshahizan/HPDP/issues) for any improvements, suggestions or errors in the content.

You can also contact me using [Linkedin](https://www.linkedin.com/in/drshahizan/) for any other queries or feedback.

[![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fdrshahizan&labelColor=%23697689&countColor=%23555555&style=plastic)](https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2Fdrshahizan)
![](https://hit.yhype.me/github/profile?user_id=81284918)
