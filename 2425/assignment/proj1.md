<a href="https://github.com/drshahizan/HPDP/stargazers"><img src="https://img.shields.io/github/stars/drshahizan/HPDP" alt="Stars Badge"/></a>
<a href="https://github.com/drshahizan/HPDP/network/members"><img src="https://img.shields.io/github/forks/drshahizan/HPDP" alt="Forks Badge"/></a>
<a href="https://github.com/drshahizan/HPDP/pulls"><img src="https://img.shields.io/github/issues-pr/drshahizan/HPDP" alt="Pull Requests Badge"/></a>
<a href="https://github.com/drshahizan/HPDP/issues"><img src="https://img.shields.io/github/issues/drshahizan/HPDP" alt="Issues Badge"/></a>
<a href="https://github.com/drshahizan/HPDP/graphs/contributors"><img alt="GitHub contributors" src="https://img.shields.io/github/contributors/drshahizan/HPDP?color=2b9348"></a>
![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fdrshahizan%2FHPDP&labelColor=%23d9e3f0&countColor=%23697689&style=flat)

# üìÑ Project 1: Optimizing High-Performance Data Processing for Large-Scale Web Crawlers

## Project Synopsis
This project introduces students to real-world applications of high-performance computing (HPC) in large-scale web data processing. Students will work collaboratively in diverse teams to design, develop, and optimize a web crawler capable of extracting a minimum of **100,000 structured records** from a **Malaysian website**. Emphasis is placed on the practical implementation of **multithreading, multiprocessing, and distributed processing** techniques to improve the efficiency and scalability of the system. 

Through hands-on experience, students will explore data collection, cleaning, transformation, and storage, while addressing technical challenges such as crawl delays, ethical scraping, and performance bottlenecks. The project culminates with a comprehensive performance evaluation comparing pre- and post-optimization results. Deliverables include a final technical report, source code, cleaned dataset, performance analysis, and a group presentation. 

This project aims to develop students' technical skills in high-performance computing, critical thinking in system optimization, and collaboration in diverse teams‚Äîkey competencies for data science professionals.

üìä **Weightage**: 15% of total course assessment  
üïì Project Duration: 4 Weeks
üìÖ **Submission Deadline**: **Friday, 16 May 2025**  
üì§ **Submission Format**: All final documents must be uploaded via e-learning and github  
üë• **Assignment Type**: **4 students per group (Max)**. 
> üìå Each group must include students from **different genders, races, or backgrounds** to encourage diversity and collaboration across cultures and perspectives.


## ‚úÖ **Student Project Checklist & Timeline Tracker**

Use this checklist to ensure your group stays on track throughout the 4-week project.

### üìÖ **Timeline & Checklist**

| Week | Task | Responsible Member(s) | Status ‚úÖ |
|------|------|------------------------|:-----------:|
| Week 1 | Form a diverse group (4 members) | All | ‚òê |
| Week 1 | Choose a Malaysian website & get approval | Group Leader | ‚òê |
| Week 1 | Identify target data fields (‚â•100,000 records) | Data Analyst | ‚òê |
| Week 1 | Design system architecture (crawler + pipeline) | Architect | ‚òê |
| Week 2 | Develop and test web crawler (initial batch) | Coder | ‚òê |
| Week 2 | Begin collecting real data (progressive storage) | All | ‚òê |
| Week 3 | Process and clean dataset (remove duplicates, standardize) | Data Analyst | ‚òê |
| Week 3 | Apply optimization (threading, Spark, Dask, etc.) | HPC Specialist | ‚òê |
| Week 3 | Benchmark performance (before vs after) | Evaluator | ‚òê |
| Week 4 | Compile results, charts, and graphs | Documentation Lead | ‚òê |
| Week 4 | Write final report | All (shared) | ‚òê |
| Week 4 | Submit report to Turnitin (by 16 May) | Group Leader | ‚òê |
| Week 4 | Submit code, dataset, and slides | All | ‚òê |
| Week 4 | Present final project (10 minutes) | All | ‚òê |

## üßæ **Sample Report Structure (Final Report)**

Your **report must be professional, complete, and easy to follow**. Below is the recommended structure:

### üóÇÔ∏è **Sections & Content**

1. **Cover Page**
   - Project Title
   - Course Name: High-Performance Data Processing
   - Group Members (Name, Matrix No.)
   - Submission Date

2. **Table of Contents**

3. **1. Introduction**
   - Background of the project
   - Objectives
   - Target website and data to be extracted

4. **2. System Design & Architecture**
   - Description of architecture (include diagram)
   - Tools and frameworks used (e.g., Python, Scrapy, Spark)
   - Roles of team members

5. **3. Data Collection**
   - Crawling method (pagination, rate-limiting, async)
   - Number of records collected
   - Ethical considerations

6. **4. Data Processing**
   - Cleaning methods
   - Data structure (CSV/JSON/database)
   - Transformation and formatting

7. **5. Optimization Techniques**
   - Methods used: multithreading, multiprocessing, Spark, etc.
   - Code overview or pseudocode of techniques applied

8. **6. Performance Evaluation**
   - Before vs after optimization
   - Time, memory, CPU usage, throughput
   - Charts and graphs

9. **7. Challenges & Limitations**
   - What didn‚Äôt go as planned
   - Any limitations of your solution

10. **8. Conclusion & Future Work**
    - Summary of findings
    - What could be improved

11. **References**

12. **Appendices**
    - Sample code snippets
    - Screenshots of output
    - Links to full code repo or dataset


## üìÅ **GitHub Folder Template submission**

When you submit your code via GitHub, follow this recommended folder structure:

```
üìÅ Project1-HPDP-WebCrawler/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ crawler/                 
‚îÇ   ‚îî‚îÄ‚îÄ main_crawler.py        
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml            
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py            
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îî‚îÄ‚îÄ raw_data.json          
‚îÇ   ‚îî‚îÄ‚îÄ cleaned_data.csv       
‚îÇ
‚îú‚îÄ‚îÄ üìÅ processing/
‚îÇ   ‚îî‚îÄ‚îÄ clean_data.py          
‚îÇ   ‚îî‚îÄ‚îÄ optimize_pipeline.py   
‚îÇ
‚îú‚îÄ‚îÄ üìÅ evaluation/
‚îÇ   ‚îî‚îÄ‚îÄ performance_before.csv 
‚îÇ   ‚îî‚îÄ‚îÄ performance_after.csv  
‚îÇ   ‚îî‚îÄ‚îÄ evaluation_charts.ipynb
‚îÇ
‚îú‚îÄ‚îÄ üìÅ report/
‚îÇ   ‚îî‚îÄ‚îÄ Final_Report.pdf       
‚îÇ   ‚îî‚îÄ‚îÄ Presentation_Slides.pptx
‚îÇ
‚îú‚îÄ‚îÄ README.md                  
‚îú‚îÄ‚îÄ requirements.txt           
‚îî‚îÄ‚îÄ LICENSE (optional)         
```

> ‚úÖ Include `README.md` that explains how to run your crawler, dependencies, and output format.

## Contribution üõ†Ô∏è
Please create an [Issue](https://github.com/drshahizan/HPDP/issues) for any improvements, suggestions or errors in the content.

You can also contact me using [Linkedin](https://www.linkedin.com/in/drshahizan/) for any other queries or feedback.

[![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fdrshahizan&labelColor=%23697689&countColor=%23555555&style=plastic)](https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2Fdrshahizan)
![](https://hit.yhype.me/github/profile?user_id=81284918)
