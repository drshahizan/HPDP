# ğŸ“Š Assignment 2: Mastering Big Data Handling ğŸš€

**Course:** *HPDP SECP3133-01*

---

### ğŸ§‘â€ğŸ¤â€ğŸ§‘ Group Members

| Name                               | Matric Number |
|------------------------------------|---------------|
| MUHAMMAD DANIAL BIN AHMAD SYAHIR  | A22EC0206 |
| MUHAMMAD ANAS BIN MOHD PIKRI      | A21SC0464 |



---

### ğŸŒŸ Introduction

Handling large-scale datasets presents real-world challenges, especially when the data exceeds system memory.  
This project explores efficient techniques for working with such datasets using information derived from the anime and entertainment domain.

We start by applying foundational strategies using **Pandas**, including:

- ğŸšª Loading only the necessary columns to reduce memory overhead  
- ğŸ“¦ Processing data in chunks for better memory management  
- ğŸ§  Converting data types to more memory-efficient formats  
- ğŸ¯ Using samples of the dataset for quicker testing and exploration

We then shift to more scalable solutions like **Dask** and **Polars**, assessing their ability to handle big data operations with better performance and parallel processing support.


---

### ğŸŒ Dataset Overview

**ğŸ“‚ Dataset:** MyAnimeList Dataset 2023  
**ğŸ”— Source:** [ğŸ“¦ Kaggle Dataset](https://www.kaggle.com/datasets/dbdmobile/myanimelist-dataset)

| Feature     | Description                                                      |
|-------------|------------------------------------------------------------------|
| ğŸ’¾ Size     | ~4GB (CSV)                                                       |
| ğŸ“ˆ Records  | Thousands of anime titles + user interaction logs                |
| ğŸ­ Domain   | Anime, Entertainment, Streaming                                  |
| ğŸ“Š Use Case | Recommendation, Popularity, Ratings, Demographic Analysis       |
| âœ… Reason    | Real-world size and diversity make it ideal for scalability tests|

---

### ğŸ› ï¸ Libraries Used (Phase 1)

| Library     | Purpose                                      |
|-------------|----------------------------------------------|
| `pandas`    | Traditional DataFrame operations             |
| `time`      | Performance benchmarking                     |
| `gc`        | Garbage collection to manage memory          |
| `dask`      | Parallel, out-of-core computation            |
| `polars`    | High-speed DataFrame operations (Rust-backed)|
| `psutil`    | Memory tracking                              |
| `matplotlib`, `seaborn` | Data visualization and analysis  |

---

### ğŸ” Project Navigation

| Resource             | Description                             | Link                                                              |
|----------------------|-----------------------------------------|-------------------------------------------------------------------|
| ğŸ“„ **Main Report**    | Full analysis, comparison, and summary  | [big_data.md](https://github.com/drshahizan/HPDP/blob/main/2425/assignment/A2/bdm/Dans/big_data.md)|
| ğŸ““ **Notebook Code**  | Full implementation in Colab            | [Open in Colab â–¶ï¸](https://colab.research.google.com/drive/1ztlLQDrfvT1gRwekZ3E_5p93nWnl6QrO?usp=sharing)|
| ğŸ“¦ **Dataset Source** | Original dataset on Kaggle              | [Go to Dataset](https://www.kaggle.com/datasets/dbdmobile/myanimelist-dataset) |

---

### ğŸ”§ Project Outcomes

- Identified limitations of Pandas on large-scale data
- Applied chunking, sampling, and optimization for efficient processing
- Successfully benchmarked Dask and Polars for time and memory
- Delivered clean, scalable workflows for big data analysis

---

### ğŸ“ Instructor Info

**Lecturer**: Dr. Mohd Shahizan Othman  
**Course**: High Performance Data Processing *(SECP3133)*  
**Institution**: Universiti Teknologi Malaysia

---

> âœ¨ *Built with ğŸ’» Python, ğŸ” curiosity, and âš™ï¸ performance-driven mindset.*

