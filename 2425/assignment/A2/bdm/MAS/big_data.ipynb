{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwWkYdALrIcI"
      },
      "source": [
        "# **Apply Big Data Handling Strategies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bIN5KLcrOXM"
      },
      "outputs": [],
      "source": [
        "# 🔽 STEP 1: Install kaggle CLI\n",
        "!pip install -q kaggle\n",
        "\n",
        "# 🔽 STEP 2: Upload kaggle.json API token\n",
        "from google.colab import files\n",
        "print(\"Please upload your kaggle.json file:\")\n",
        "files.upload()\n",
        "\n",
        "# 🔽 STEP 3: Set up Kaggle CLI config\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# 🔽 STEP 4: Download your desired dataset\n",
        "# Replace with your actual competition or dataset name\n",
        "!kaggle datasets download mkechinov/ecommerce-behavior-data-from-multi-category-store\n",
        "\n",
        "!unzip ecommerce-behavior-data-from-multi-category-store.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import dask.dataframe as dd\n",
        "import polars as pl\n",
        "\n",
        "# Constants\n",
        "FILENAME = '2019-Oct.csv'\n",
        "USECOLS = ['event_type', 'price']\n",
        "TARGET_EVENT_TYPE = 'purchase'\n",
        "MEASUREMENT_COLUMN = 'price'\n",
        "CHUNKSIZE = 100_000\n",
        "DTYPE_MAP = {'event_type': 'category', 'price': 'float32'}"
      ],
      "metadata": {
        "id": "sclgu9M56YDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_strategy_results(name, mean_price, mem_usage, exec_time, throughput):\n",
        "    \"\"\"\n",
        "    Prints consistent output across all strategies\n",
        "    \"\"\"\n",
        "    print(f\"📊 {name}\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Mean Purchase Price : {mean_price:.2f}\")\n",
        "    print(f\"Memory Usage        : {mem_usage:.2f} MB\")\n",
        "    print(f\"Execution Time      : {exec_time:.2f} seconds\")\n",
        "    print(f\"Throughput          : {throughput:.0f} rows/sec\")\n",
        "    print(\"-\" * 50 + \"\\n\")\n",
        "    return {\n",
        "        \"strategy\": name,\n",
        "        \"mean_price\": mean_price,\n",
        "        \"memory_usage_mb\": mem_usage,\n",
        "        \"execution_time_sec\": exec_time,\n",
        "        \"throughput_rows_per_sec\": throughput\n",
        "    }\n",
        "\n",
        "def compute_mean_purchase_price(df):\n",
        "    return df[df['event_type'] == TARGET_EVENT_TYPE][MEASUREMENT_COLUMN].mean()\n",
        "\n",
        "results = []"
      ],
      "metadata": {
        "id": "bgbE03FD60kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtbUpO0El_A6"
      },
      "outputs": [],
      "source": [
        "# 🧪 Load Sample for Inspection\n",
        "df_sample = pd.read_csv(FILENAME)\n",
        "print(\"📊\" + \"=\"*40)\n",
        "print(\"     🔍 DATASET INSPECTION REPORT\")\n",
        "print(\"📊\" + \"=\"*40 + \"\\n\")\n",
        "print(\"🧾 Shape (Rows, Columns):\")\n",
        "print(f\"    ➤ {df_sample.shape[0]} rows, {df_sample.shape[1]} columns\\n\")\n",
        "print(\"📌 Column Names:\")\n",
        "print(\"    ➤ \" + \"\\n    ➤ \".join(df_sample.columns.tolist()) + \"\\n\")\n",
        "print(\"⚙️ Data Types:\")\n",
        "for col, dtype in df_sample.dtypes.items():\n",
        "    print(f\"    ➤ {col.ljust(20)} : {dtype}\")\n",
        "print(\"\\n💾 Memory Usage (MB):\")\n",
        "mem_usage = df_sample.memory_usage(deep=True) / (1024 ** 2)\n",
        "for col, usage in mem_usage.items():\n",
        "    print(f\"    ➤ {col.ljust(20)} : {usage:.4f} MB\")\n",
        "print(f\"\\n    🧮 Total Memory : {mem_usage.sum():.4f} MB\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📊 Strategy 1: Load Less Data\n",
        "df_lite = pd.read_csv(FILENAME, usecols=USECOLS, nrows=100_000)\n",
        "start = time.time()\n",
        "mean_lite = compute_mean_purchase_price(df_lite)\n",
        "time_lite = time.time() - start\n",
        "mem_lite = df_lite.memory_usage(deep=True).sum() / (1024 ** 2)\n",
        "throughput_lite = len(df_lite) / time_lite if time_lite > 0 else float('nan')\n",
        "results.append(print_strategy_results(\"Strategy 1: Load Less Data\", mean_lite, mem_lite, time_lite, throughput_lite))"
      ],
      "metadata": {
        "id": "n4wWcFVwaiCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G609NZS0VCI"
      },
      "outputs": [],
      "source": [
        "# 📊 Strategy 2: Optimize Data Types\n",
        "df_optimized = pd.read_csv(FILENAME, usecols=USECOLS, dtype=DTYPE_MAP, nrows=100_000)\n",
        "start = time.time()\n",
        "mean_opt = compute_mean_purchase_price(df_optimized)\n",
        "time_opt = time.time() - start\n",
        "mem_opt = df_optimized.memory_usage(deep=True).sum() / (1024 ** 2)\n",
        "throughput_opt = len(df_optimized) / time_opt if time_opt > 0 else float('nan')\n",
        "results.append(print_strategy_results(\"Strategy 2: Optimize Data Types\", mean_opt, mem_opt, time_opt, throughput_opt))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📊 Strategy 3: Sampling\n",
        "df_sampled = df_optimized.sample(frac=0.01, random_state=42)\n",
        "start = time.time()\n",
        "mean_samp = compute_mean_purchase_price(df_sampled)\n",
        "time_samp = time.time() - start\n",
        "mem_samp = df_sampled.memory_usage(deep=True).sum() / (1024 ** 2)\n",
        "throughput_samp = len(df_sampled) / time_samp if time_samp > 0 else float('nan')\n",
        "results.append(print_strategy_results(\"Strategy 3: Sampling\", mean_samp, mem_samp, time_samp, throughput_samp))"
      ],
      "metadata": {
        "id": "nuuyOY1wgJWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📊 Strategy 4: Chunked Processing\n",
        "total_sum = 0\n",
        "total_count = 0\n",
        "peak_mem = 0\n",
        "start = time.time()\n",
        "\n",
        "for chunk in pd.read_csv(FILENAME, usecols=USECOLS, dtype=DTYPE_MAP, chunksize=CHUNKSIZE):\n",
        "    filtered = chunk[chunk['event_type'] == TARGET_EVENT_TYPE]\n",
        "    total_sum += filtered['price'].sum()\n",
        "    total_count += len(filtered)\n",
        "    mem = chunk.memory_usage(deep=True).sum() / (1024 ** 2)\n",
        "    peak_mem = max(peak_mem, mem)\n",
        "\n",
        "mean_chunk = total_sum / total_count\n",
        "time_chunk = time.time() - start\n",
        "throughput_chunk = total_count / time_chunk if time_chunk > 0 else float('nan')\n",
        "results.append(print_strategy_results(\"Strategy 4: Chunked Processing\", mean_chunk, peak_mem, time_chunk, throughput_chunk))"
      ],
      "metadata": {
        "id": "NrYVEB34Br2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  📊 Strategy 5a: Parallel Processing with Dask\n",
        "def run_dask():\n",
        "    start = time.time()\n",
        "    ddf = dd.read_csv(FILENAME, usecols=USECOLS)\n",
        "    mean = ddf[ddf['event_type'] == TARGET_EVENT_TYPE][MEASUREMENT_COLUMN].mean().compute()\n",
        "    shape = (len(ddf), len(ddf.columns))\n",
        "    mem = ddf.memory_usage(index=True, deep=True).sum().compute() / (1024 ** 2)\n",
        "    t = time.time() - start\n",
        "    throughput = shape[0] / t if t > 0 else float('nan')\n",
        "    return {\"mean\": mean, \"shape\": shape, \"mem\": mem, \"time\": t, \"throughput\": throughput}\n",
        "\n",
        "dask_result= run_dask()\n",
        "results.append(print_strategy_results(\"Strategy 5a: Dask Processing\", dask_result[\"mean\"], dask_result[\"mem\"], dask_result[\"time\"], dask_result[\"throughput\"]))"
      ],
      "metadata": {
        "id": "N2bIs0vPBuZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xCQA90EGIZp"
      },
      "outputs": [],
      "source": [
        "# Strategy 5b: Polars\n",
        "def run_polars():\n",
        "    start = time.time()\n",
        "    df_pl = pl.read_csv(FILENAME, columns=USECOLS)\n",
        "    mean = df_pl.filter(pl.col('event_type') == TARGET_EVENT_TYPE)[MEASUREMENT_COLUMN].cast(pl.Float64).mean()\n",
        "    shape = df_pl.shape\n",
        "    mem = df_pl.estimated_size() / (1024 ** 2)\n",
        "    t = time.time() - start\n",
        "    throughput = shape[0] / t if t > 0 else float('nan')\n",
        "    return {\"mean\": mean, \"shape\": shape, \"mem\": mem, \"time\": t, \"throughput\": throughput}\n",
        "\n",
        "polars_result = run_polars()\n",
        "results.append(print_strategy_results(\"Strategy 5b: Polars Processing\", polars_result[\"mean\"], polars_result[\"mem\"], polars_result[\"time\"], polars_result[\"throughput\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VUCFMOzGT4P"
      },
      "outputs": [],
      "source": [
        "# 📊 Final Comparison Table\n",
        "!pip install pandas dask polars tabulate\n",
        "!pip install pandas dask polars tabulate matplotlib\n",
        "\n",
        "from tabulate import tabulate\n",
        "\n",
        "table_data = [\n",
        "    [\"Load Less Data\", mem_lite, time_lite, throughput_lite],\n",
        "    [\"Optimize Data Types\", mem_opt, time_opt, throughput_opt],\n",
        "    [\"Sampling\", mem_samp, time_samp, throughput_samp],\n",
        "    [\"Chunked Processing\", peak_mem, time_chunk, throughput_chunk],\n",
        "    [\"Dask\", dask_result[\"mem\"], dask_result[\"time\"], dask_result[\"throughput\"]],\n",
        "    [\"Polars\", polars_result[\"mem\"], polars_result[\"time\"], polars_result[\"throughput\"]]\n",
        "]\n",
        "\n",
        "headers = [\"Strategy\", \"Memory Usage (MB)\", \"Execution Time (s)\", \"Throughput (rows/sec)\"]\n",
        "\n",
        "print(\"\\n📈 FINAL COMPARISON TABLE\")\n",
        "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uw9p_I2eGWFZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Memory Usage\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(results_df['strategy'], results_df['memory_usage_mb'], color='skyblue')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylabel('Memory Usage (MB)')\n",
        "plt.title('📊 Memory Usage by Strategy')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Execution Time\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(results_df['strategy'], results_df['execution_time_sec'], color='salmon')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylabel('Execution Time (seconds)')\n",
        "plt.title('⏱️ Execution Time by Strategy')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Throughput\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(results_df['strategy'], results_df['throughput_rows_per_sec'], color='lightgreen')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylabel('Throughput (rows/sec)')\n",
        "plt.title('🚀 Throughput by Strategy')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}