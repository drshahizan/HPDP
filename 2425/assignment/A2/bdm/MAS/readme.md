# 📘 Assignment 2: Mastering Big Data Handling  
### Group Members:
| Name              | Matric No       |
|-------------------|-----------------|
| MAISARAH BINTI RIZAL   | A22EC0192      |
| NADHRAH NURSABRINA BINTI ZULAINI  | A22EC0224    |

📅 **Submission Date:** 4 June 2025  



## 📌 Overview

This repository contains our submission for **Assignment 2: Mastering Big Data Handling**, where we explored strategies for efficiently working with large datasets that exceed traditional memory limits.

We used Python tools like **Pandas**, **Dask**, and **Polars** to process a dataset larger than 700MB, and compared performance across methods.



## 🧾 Dataset Used

| Property | Description |
|---------|-------------|
| **Name** | [E-Commerce Behavior Data from Multi Category Store](https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store) |
| **Source** | [Kaggle Dataset](https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store)  |
| **File Used** | `2019-Oct.csv` |
| **Size** | ~1.3 GB (full file), ~700+ MB usable data |
| **Columns Used** | `event_time`, `event_type`, `category_code`, `brand`, `price` |
| **Domain** | E-commerce user behavior tracking |



## 📁 Folder Structure
