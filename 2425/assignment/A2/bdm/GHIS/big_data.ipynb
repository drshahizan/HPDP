{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEbxo5oOuyp8",
        "outputId": "6dfcc09a-434f-4658-b0e7-3b03766d063f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/drive/MyDrive/archive_3.zip'\n",
        "extract_folder = '/content/github_issues/'\n",
        "\n",
        "!unzip -q \"{zip_path}\" -d \"{extract_folder}\""
      ],
      "metadata": {
        "id": "ceg5D_6pv0oC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = extract_folder + 'github_issues.csv'"
      ],
      "metadata": {
        "id": "zmuuXt-xwB3n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WpdgKzFsiCx",
        "outputId": "4ba53f5d-2f6d-4d5a-8e94-f5e1a4a54ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (18.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load Less Data\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/github_issues/github_issues.csv'  # update to your actual file path\n",
        "\n",
        "cols_to_load = ['issue_url', 'issue_title', 'body']\n",
        "\n",
        "df = pd.read_csv(file_path, usecols=cols_to_load, nrows=100000)\n",
        "\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waFS69duMsXQ",
        "outputId": "30485445-2ea8-4224-bb72-d1c52974645e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 3)\n",
            "                                           issue_url  \\\n",
            "0  \"https://github.com/zhangyuanwei/node-images/i...   \n",
            "1     \"https://github.com/Microsoft/pxt/issues/2543\"   \n",
            "2  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
            "3  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
            "4  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
            "\n",
            "                                         issue_title  \\\n",
            "0  can't load the addon. issue to: https://github...   \n",
            "1  hcl accessibility a11yblocking a11ymas mas4.2....   \n",
            "2  issue 1265: issue 1264: issue 1261: issue 1260...   \n",
            "3  issue 1266: issue 1263: issue 1262: issue 1259...   \n",
            "4  issue 1288: issue 1285: issue 1284: issue 1281...   \n",
            "\n",
            "                                                body  \n",
            "0  can't load the addon. issue to: https://github...  \n",
            "1  user experience: user who depends on screen re...  \n",
            "2  ┆attachments: <a href= https:& x2f;& x2f;githu...  \n",
            "3  gitlo = github x trello\\n---\\nthis board is no...  \n",
            "4  ┆attachments: <a href= https:& x2f;& x2f;githu...  \n",
            "issue_url      object\n",
            "issue_title    object\n",
            "body           object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Chunking\n",
        "import pandas as pd\n",
        "\n",
        "chunksize = 100_000  # Adjust if needed\n",
        "chunk_list = []\n",
        "\n",
        "for i, chunk in enumerate(pd.read_csv(\n",
        "    csv_path,\n",
        "    encoding='utf-8',\n",
        "    engine='python',        # Use Python engine for tolerant parsing\n",
        "    on_bad_lines='skip',    # Skip bad lines to avoid crashing\n",
        "    chunksize=chunksize\n",
        "    # low_memory parameter removed here!\n",
        ")):\n",
        "    print(f\"Processing chunk {i+1} with shape {chunk.shape}\")\n",
        "\n",
        "    if 'state' in chunk.columns:\n",
        "        filtered_chunk = chunk[chunk['state'] == 'open']\n",
        "    else:\n",
        "        filtered_chunk = chunk\n",
        "\n",
        "    chunk_list.append(filtered_chunk.head(100))\n",
        "\n",
        "    if i == 4:  # For demo, stop after 5 chunks\n",
        "        break\n",
        "\n",
        "df_sample = pd.concat(chunk_list)\n",
        "print(f\"\\nSample dataframe shape: {df_sample.shape}\")\n",
        "df_sample.head()"
      ],
      "metadata": {
        "id": "aLOixokewEQz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "1b7776a8-3609-4df4-d570-3052c0d8007d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing chunk 1 with shape (100000, 3)\n",
            "Processing chunk 2 with shape (100000, 3)\n",
            "Processing chunk 3 with shape (100000, 3)\n",
            "Processing chunk 4 with shape (100000, 3)\n",
            "Processing chunk 5 with shape (100000, 3)\n",
            "\n",
            "Sample dataframe shape: (500, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           issue_url  \\\n",
              "0  \"https://github.com/zhangyuanwei/node-images/i...   \n",
              "1     \"https://github.com/Microsoft/pxt/issues/2543\"   \n",
              "2  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
              "3  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
              "4  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
              "\n",
              "                                         issue_title  \\\n",
              "0  can't load the addon. issue to: https://github...   \n",
              "1  hcl accessibility a11yblocking a11ymas mas4.2....   \n",
              "2  issue 1265: issue 1264: issue 1261: issue 1260...   \n",
              "3  issue 1266: issue 1263: issue 1262: issue 1259...   \n",
              "4  issue 1288: issue 1285: issue 1284: issue 1281...   \n",
              "\n",
              "                                                body  \n",
              "0  can't load the addon. issue to: https://github...  \n",
              "1  user experience: user who depends on screen re...  \n",
              "2  ┆attachments: <a href= https:& x2f;& x2f;githu...  \n",
              "3  gitlo = github x trello\\n---\\nthis board is no...  \n",
              "4  ┆attachments: <a href= https:& x2f;& x2f;githu...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0beb03ee-478f-4396-9a94-c5f96d945037\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>issue_url</th>\n",
              "      <th>issue_title</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"https://github.com/zhangyuanwei/node-images/i...</td>\n",
              "      <td>can't load the addon. issue to: https://github...</td>\n",
              "      <td>can't load the addon. issue to: https://github...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"https://github.com/Microsoft/pxt/issues/2543\"</td>\n",
              "      <td>hcl accessibility a11yblocking a11ymas mas4.2....</td>\n",
              "      <td>user experience: user who depends on screen re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"https://github.com/MatisiekPL/Czekolada/issue...</td>\n",
              "      <td>issue 1265: issue 1264: issue 1261: issue 1260...</td>\n",
              "      <td>┆attachments: &lt;a href= https:&amp; x2f;&amp; x2f;githu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"https://github.com/MatisiekPL/Czekolada/issue...</td>\n",
              "      <td>issue 1266: issue 1263: issue 1262: issue 1259...</td>\n",
              "      <td>gitlo = github x trello\\n---\\nthis board is no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"https://github.com/MatisiekPL/Czekolada/issue...</td>\n",
              "      <td>issue 1288: issue 1285: issue 1284: issue 1281...</td>\n",
              "      <td>┆attachments: &lt;a href= https:&amp; x2f;&amp; x2f;githu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0beb03ee-478f-4396-9a94-c5f96d945037')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0beb03ee-478f-4396-9a94-c5f96d945037 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0beb03ee-478f-4396-9a94-c5f96d945037');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-35b037d0-7862-4b77-a392-c0234646cd44\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35b037d0-7862-4b77-a392-c0234646cd44')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-35b037d0-7862-4b77-a392-c0234646cd44 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_sample",
              "summary": "{\n  \"name\": \"df_sample\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"issue_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"\\\"https://github.com/raksonibs/faker-elixir/issues/1\\\"\",\n          \"\\\"https://github.com/MatisiekPL/Czekolada/issues/2213\\\"\",\n          \"\\\"https://github.com/momentumfrc/Scouting-Website/issues/14\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"issue_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 493,\n        \"samples\": [\n          \"some? key bindings don't follow keyboard layout on osx\",\n          \"issue 2212: issue 2209: issue 2208: issue 2206: issue 2203: issue 2202: issue 2199: issue 2198: issue 2195: issue 2194: issue 2191: issue 2189: issue 2188: issue 2185: issue 2184: issue 2181: issue 2180: issue 2177: issue 2175: issue 2173: issue 2172: issu\",\n          \"can i control the resolution of each level?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 497,\n        \"samples\": [\n          \"do you want to request a feature or report a bug ? feature what is the current behavior? we don't look at the default trace for certain potentially harmful dbcc events what is the expected behavior? we should get an overall count of non-checkdb related events and flag certain lousy ones. which versions of sql server and which os are affected by this issue? did this work in previous versions of our procedures? all\",\n          \"gitlo = github x trello\\n---\\nthis board is now linked with https://github.com/matisiekpl/czekolada , any update on the issue tracker will be sync to this board. -------\\nvia trello, you can: --- __\\u270d create github issues__ - add a card in the corresponding column, an issue will be created in github ! add an issue http://i.imgur.com/yewicu8.gif ------- __\\u2710 comment on github issues__ - just comment as you always do in a card ! comment on an issue http://i.imgur.com/jdnjscf.gif ------- __\\u27a6 close opened issues__ - move issue cards to close list - of course you can reopen them by dragging them out of close list ! close an issue http://i.imgur.com/opaazo8.gif ------- __\\u2715 close pull requests__ - move pr cards to close list - important: you can not merge a pr via trello ! close pr http://i.imgur.com/nras2dg.gif __\\u271a__ add any custom columns you need - the column will be sync to github as a label ------- default columns\\n---\\nwe've set up default columns for you - please help keeping them in place ; you can also add your custom columns to enhance your work flow. ! add a column http://i.imgur.com/1rxnqcv.gif ------- dashboard & settings\\n---\\nfor the owner of the project, just visit http://gitlo.co to update the settings. ------- want more?\\n---\\nlet us know at http://smarturl.it/gitlo-feedback or mail us at gitlo@oursky.com \\u2506attachments: <a href= https:& x2f;& x2f;github.com& x2f;matisiekpl& x2f;czekolada& x2f;issues& x2f;2212 >https:& x2f;& x2f;github.com& x2f;matisiekpl& x2f;czekolada& x2f;issues& x2f;2212</a>\",\n          \"when editing a tageler that happens in the past, i get a button 'aktueller tageler' in the top. but when i click it, nothing happens. i can go back to the previous view, using the 'cancel' button, but since the button doesn't do anything, we should just hide it.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Optimize Data Types\n",
        "import pandas as pd\n",
        "\n",
        "def optimize_dtypes(df):\n",
        "    cat_cols = ['state', 'author_association', 'repository_url']\n",
        "    for col in cat_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    int_cols = ['comments', 'id']\n",
        "    for col in int_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce', downcast='integer')\n",
        "\n",
        "    float_cols = []\n",
        "    for col in float_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce', downcast='float')\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage\n",
        "df_sample = optimize_dtypes(df_sample)\n",
        "print(df_sample.info(memory_usage='deep'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvy_xA6Vphow",
        "outputId": "2e725db7-ca66-4306-a1c1-a3a7fe1c8c0b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 500 entries, 0 to 400099\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   issue_url    500 non-null    object\n",
            " 1   issue_title  500 non-null    object\n",
            " 2   body         500 non-null    object\n",
            "dtypes: object(3)\n",
            "memory usage: 639.5 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Sampling\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Print original data shape\n",
        "print(\"Original dataframe shape:\", df_sample.shape)\n",
        "\n",
        "# --- RANDOM SAMPLING ---\n",
        "random_sample_frac = 0.2  # 20%\n",
        "random_sample = df_sample.sample(frac=random_sample_frac, random_state=42)\n",
        "\n",
        "print(f\"\\nRandom sample shape ({int(random_sample_frac*100)}%):\", random_sample.shape)\n",
        "print(\"Random sample preview:\")\n",
        "print(random_sample.head())\n",
        "\n",
        "# --- STRATIFIED SAMPLING ---\n",
        "\n",
        "# Check if your dataframe has a suitable categorical column for stratification\n",
        "stratify_col = 'state'  # Change this to your categorical column name\n",
        "\n",
        "if stratify_col in df_sample.columns:\n",
        "    # First check counts per group to ensure enough samples per group\n",
        "    print(\"\\nValue counts before filtering:\")\n",
        "    print(df_sample[stratify_col].value_counts())\n",
        "\n",
        "    # Filter out rare groups with fewer than 2 samples (to avoid errors)\n",
        "    valid_groups = df_sample[stratify_col].value_counts()[lambda x: x >= 2].index\n",
        "    df_filtered = df_sample[df_sample[stratify_col].isin(valid_groups)]\n",
        "\n",
        "    print(\"\\nData shape after filtering rare groups:\", df_filtered.shape)\n",
        "\n",
        "    # Stratified split: keep 20% stratified by the categorical column\n",
        "    strat_sample, _ = train_test_split(\n",
        "        df_filtered,\n",
        "        test_size=0.8,\n",
        "        stratify=df_filtered[stratify_col],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\nStratified sample shape ({int(random_sample_frac*100)}%):\", strat_sample.shape)\n",
        "    print(f\"Stratified sample value counts ({stratify_col}):\")\n",
        "    print(strat_sample[stratify_col].value_counts())\n",
        "\n",
        "    print(\"\\nStratified sample preview:\")\n",
        "    print(strat_sample.head())\n",
        "\n",
        "else:\n",
        "    print(f\"\\nColumn '{stratify_col}' not found in dataframe for stratified sampling.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbn-JYGapmA4",
        "outputId": "9ce82e57-b2b7-4f83-ad83-07d3165dc518"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataframe shape: (500, 3)\n",
            "\n",
            "Random sample shape (20%): (100, 3)\n",
            "Random sample preview:\n",
            "                                                issue_url  \\\n",
            "300061  \"https://github.com/raksonibs/faker-elixir/iss...   \n",
            "73      \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
            "300074  \"https://github.com/momentumfrc/Scouting-Websi...   \n",
            "100055  \"https://github.com/Intel-bigdata/OAP/issues/255\"   \n",
            "100004  \"https://github.com/stavarengo/php-sigep/issue...   \n",
            "\n",
            "                                              issue_title  \\\n",
            "300061        can you please add a faker for filesystem ?   \n",
            "73      issue 2212: issue 2209: issue 2208: issue 2206...   \n",
            "300074        can't delete search bar contents in firefox   \n",
            "100055                         oap release 0.1 check list   \n",
            "100004                         nova etiqueta dos correios   \n",
            "\n",
            "                                                     body  \n",
            "300061  can you please add a faker module for filesyst...  \n",
            "73      gitlo = github x trello\\n---\\nthis board is no...  \n",
            "300074  the issue: - after entering a number, you cann...  \n",
            "100055  below is lists i can think of for now. i will ...  \n",
            "100004  alguem esta sabendo sobre o novo modelo de eti...  \n",
            "\n",
            "Column 'state' not found in dataframe for stratified sampling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Dataframe\n",
        "import pandas as pd\n",
        "import dask.dataframe as dd\n",
        "\n",
        "csv_path = '/content/github_issues/github_issues.csv'\n",
        "cleaned_path = '/content/github_issues/github_issues_cleaned.csv'\n",
        "\n",
        "chunk_size = 100_000\n",
        "\n",
        "# Clean in chunks, write to cleaned_path\n",
        "with pd.read_csv(csv_path, engine='python', on_bad_lines='skip', encoding='utf-8', chunksize=chunk_size) as reader:\n",
        "    for i, chunk in enumerate(reader):\n",
        "        chunk.to_csv(cleaned_path, mode='a', index=False, header=(i==0))\n",
        "        print(f\"Cleaned chunk {i+1}\")\n",
        "\n",
        "# Now read cleaned CSV with Dask\n",
        "cols_to_use = ['issue_url', 'issue_title', 'body']\n",
        "ddf = dd.read_csv(\n",
        "    cleaned_path,\n",
        "    usecols=cols_to_use,\n",
        "    dtype='object',\n",
        "    assume_missing=True,\n",
        "    encoding='utf-8',\n",
        "    blocksize='16MB'\n",
        ")\n",
        "\n",
        "print(ddf.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM1ZsLPcprSY",
        "outputId": "427570db-26d2-4c62-b029-eb9d7df62fb8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned chunk 1\n",
            "Cleaned chunk 2\n",
            "Cleaned chunk 3\n",
            "Cleaned chunk 4\n",
            "Cleaned chunk 5\n",
            "Cleaned chunk 6\n",
            "Cleaned chunk 7\n",
            "Cleaned chunk 8\n",
            "Cleaned chunk 9\n",
            "Cleaned chunk 10\n",
            "Cleaned chunk 11\n",
            "Cleaned chunk 12\n",
            "Cleaned chunk 13\n",
            "Cleaned chunk 14\n",
            "Cleaned chunk 15\n",
            "Cleaned chunk 16\n",
            "Cleaned chunk 17\n",
            "Cleaned chunk 18\n",
            "Cleaned chunk 19\n",
            "Cleaned chunk 20\n",
            "Cleaned chunk 21\n",
            "Cleaned chunk 22\n",
            "Cleaned chunk 23\n",
            "Cleaned chunk 24\n",
            "Cleaned chunk 25\n",
            "Cleaned chunk 26\n",
            "Cleaned chunk 27\n",
            "Cleaned chunk 28\n",
            "Cleaned chunk 29\n",
            "Cleaned chunk 30\n",
            "Cleaned chunk 31\n",
            "Cleaned chunk 32\n",
            "Cleaned chunk 33\n",
            "Cleaned chunk 34\n",
            "Cleaned chunk 35\n",
            "Cleaned chunk 36\n",
            "Cleaned chunk 37\n",
            "Cleaned chunk 38\n",
            "Cleaned chunk 39\n",
            "Cleaned chunk 40\n",
            "Cleaned chunk 41\n",
            "Cleaned chunk 42\n",
            "Cleaned chunk 43\n",
            "Cleaned chunk 44\n",
            "Cleaned chunk 45\n",
            "Cleaned chunk 46\n",
            "Cleaned chunk 47\n",
            "Cleaned chunk 48\n",
            "Cleaned chunk 49\n",
            "Cleaned chunk 50\n",
            "Cleaned chunk 51\n",
            "Cleaned chunk 52\n",
            "Cleaned chunk 53\n",
            "Cleaned chunk 54\n",
            "                                           issue_url  \\\n",
            "0  \"https://github.com/zhangyuanwei/node-images/i...   \n",
            "1     \"https://github.com/Microsoft/pxt/issues/2543\"   \n",
            "2  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
            "3  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
            "4  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
            "\n",
            "                                         issue_title  \\\n",
            "0  can't load the addon. issue to: https://github...   \n",
            "1  hcl accessibility a11yblocking a11ymas mas4.2....   \n",
            "2  issue 1265: issue 1264: issue 1261: issue 1260...   \n",
            "3  issue 1266: issue 1263: issue 1262: issue 1259...   \n",
            "4  issue 1288: issue 1285: issue 1284: issue 1281...   \n",
            "\n",
            "                                                body  \n",
            "0  can't load the addon. issue to: https://github...  \n",
            "1  user experience: user who depends on screen re...  \n",
            "2  ┆attachments: <a href= https:& x2f;& x2f;githu...  \n",
            "3  gitlo = github x trello\n",
            "---\n",
            "this board is now ...  \n",
            "4  ┆attachments: <a href= https:& x2f;& x2f;githu...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Pandas\n",
        "import pandas as pd\n",
        "import time\n",
        "import psutil\n",
        "import threading\n",
        "\n",
        "# File path\n",
        "csv_path = '/content/github_issues/github_issues.csv'\n",
        "\n",
        "# Monitoring setup\n",
        "monitoring = True\n",
        "performance_logs = []\n",
        "\n",
        "def monitor_performance(log_list, interval=0.5):\n",
        "    proc = psutil.Process()\n",
        "    while monitoring:\n",
        "        mem = proc.memory_info().rss / (1024*1024)  # MB\n",
        "        cpu = proc.cpu_percent(interval=None)      # %\n",
        "        log_list.append((time.time(), mem, cpu))\n",
        "        time.sleep(interval)\n",
        "\n",
        "monitor_thread = threading.Thread(target=monitor_performance, args=(performance_logs,))\n",
        "monitor_thread.start()\n",
        "\n",
        "start_time = time.time()\n",
        "print(\"===== Pandas Processing Started =====\")\n",
        "\n",
        "# Load entire dataset (traditional)\n",
        "df = pd.read_csv(csv_path, encoding='utf-8')\n",
        "\n",
        "print(f\"Loaded {len(df)} records.\")\n",
        "\n",
        "# Basic cleaning: fill missing, strip strings, drop duplicates\n",
        "df.fillna({'issue_title': 'No Title', 'body': ''}, inplace=True)\n",
        "for col in ['issue_title', 'body']:\n",
        "    df[col] = df[col].astype(str).str.strip()\n",
        "\n",
        "initial_len = len(df)\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(f\"Removed {initial_len - len(df)} duplicate rows.\")\n",
        "\n",
        "monitoring = False\n",
        "monitor_thread.join()\n",
        "end_time = time.time()\n",
        "\n",
        "# Performance metrics\n",
        "total_time = end_time - start_time\n",
        "num_records = len(df)\n",
        "throughput = num_records / total_time\n",
        "peak_mem = max([m for _, m, _ in performance_logs])\n",
        "avg_mem = sum([m for _, m, _ in performance_logs]) / len(performance_logs)\n",
        "peak_cpu = max([c for _, _, c in performance_logs])\n",
        "avg_cpu = sum([c for _, _, c in performance_logs]) / len(performance_logs)\n",
        "\n",
        "print(\"\\n===== Pandas Performance Summary =====\")\n",
        "print(f\"Execution time: {total_time:.2f} seconds\")\n",
        "print(f\"Records processed: {num_records}\")\n",
        "print(f\"Throughput: {throughput:.2f} records/second\")\n",
        "print(f\"Average memory usage: {avg_mem:.2f} MB\")\n",
        "print(f\"Peak memory usage: {peak_mem:.2f} MB\")\n",
        "print(f\"Average CPU usage: {avg_cpu:.2f}%\")\n",
        "print(f\"Peak CPU usage: {peak_cpu:.2f}%\")\n",
        "print(\"Ease of Processing: Simple to use, widely known, but may be slow and memory intensive for very large datasets.\")\n",
        "print(\"======================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbTB7QNfqvtT",
        "outputId": "c565e714-1c39-4df2-a110-2aef58a3e276"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Pandas Processing Started =====\n",
            "Loaded 5332153 records.\n",
            "Removed 5097 duplicate rows.\n",
            "\n",
            "===== Pandas Performance Summary =====\n",
            "Execution time: 87.15 seconds\n",
            "Records processed: 5327056\n",
            "Throughput: 61126.66 records/second\n",
            "Average memory usage: 4012.66 MB\n",
            "Peak memory usage: 5494.21 MB\n",
            "Average CPU usage: 98.10%\n",
            "Peak CPU usage: 224.50%\n",
            "Ease of Processing: Simple to use, widely known, but may be slow and memory intensive for very large datasets.\n",
            "======================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Polars\n",
        "import polars as pl\n",
        "import time\n",
        "import psutil\n",
        "import threading\n",
        "\n",
        "csv_path = '/content/github_issues/github_issues.csv'\n",
        "\n",
        "monitoring = True\n",
        "performance_logs = []\n",
        "\n",
        "def monitor_performance(log_list, interval=0.5):\n",
        "    proc = psutil.Process()\n",
        "    while monitoring:\n",
        "        mem = proc.memory_info().rss / (1024*1024)  # MB\n",
        "        cpu = proc.cpu_percent(interval=None)      # %\n",
        "        log_list.append((time.time(), mem, cpu))\n",
        "        time.sleep(interval)\n",
        "\n",
        "monitor_thread = threading.Thread(target=monitor_performance, args=(performance_logs,))\n",
        "monitor_thread.start()\n",
        "\n",
        "start_time = time.time()\n",
        "print(\"===== Polars Processing Started =====\")\n",
        "\n",
        "df = pl.read_csv(csv_path)\n",
        "\n",
        "print(f\"Loaded {df.height} records.\")\n",
        "\n",
        "# Fill missing\n",
        "fill_dict = {'issue_title': 'No Title', 'body': ''}\n",
        "for col, val in fill_dict.items():\n",
        "    if col in df.columns:\n",
        "        df = df.with_columns(pl.col(col).fill_null(val))\n",
        "\n",
        "# Strip whitespace\n",
        "for col in ['issue_title', 'body']:\n",
        "    if col in df.columns:\n",
        "        df = df.with_columns(pl.col(col).str.strip_chars())\n",
        "\n",
        "# Drop duplicates\n",
        "initial_len = df.height\n",
        "df = df.unique()\n",
        "print(f\"Removed {initial_len - df.height} duplicate rows.\")\n",
        "\n",
        "monitoring = False\n",
        "monitor_thread.join()\n",
        "end_time = time.time()\n",
        "\n",
        "total_time = end_time - start_time\n",
        "num_records = df.height\n",
        "throughput = num_records / total_time\n",
        "peak_mem = max([m for _, m, _ in performance_logs])\n",
        "avg_mem = sum([m for _, m, _ in performance_logs]) / len(performance_logs)\n",
        "peak_cpu = max([c for _, _, c in performance_logs])\n",
        "avg_cpu = sum([c for _, _, c in performance_logs]) / len(performance_logs)\n",
        "\n",
        "print(\"\\n===== Polars Performance Summary =====\")\n",
        "print(f\"Execution time: {total_time:.2f} seconds\")\n",
        "print(f\"Records processed: {num_records}\")\n",
        "print(f\"Throughput: {throughput:.2f} records/second\")\n",
        "print(f\"Average memory usage: {avg_mem:.2f} MB\")\n",
        "print(f\"Peak memory usage: {peak_mem:.2f} MB\")\n",
        "print(f\"Average CPU usage: {avg_cpu:.2f}%\")\n",
        "print(f\"Peak CPU usage: {peak_cpu:.2f}%\")\n",
        "print(\"Ease of Processing: Fast and memory efficient, but requires learning Polars API.\")\n",
        "print(\"======================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u34iqSlWqlSF",
        "outputId": "391c0701-6eb7-4195-b57c-74a63d02605e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Polars Processing Started =====\n",
            "Loaded 5332153 records.\n",
            "Removed 5097 duplicate rows.\n",
            "\n",
            "===== Polars Performance Summary =====\n",
            "Execution time: 36.17 seconds\n",
            "Records processed: 5327056\n",
            "Throughput: 147290.82 records/second\n",
            "Average memory usage: 3790.27 MB\n",
            "Peak memory usage: 10736.56 MB\n",
            "Average CPU usage: 65.79%\n",
            "Peak CPU usage: 193.80%\n",
            "Ease of Processing: Fast and memory efficient, but requires learning Polars API.\n",
            "======================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title PyArrow\n",
        "import os\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.csv as pv\n",
        "import pyarrow.compute as pc\n",
        "import time, psutil, threading\n",
        "\n",
        "csv_path = '/content/github_issues/github_issues.csv'\n",
        "cleaned_csv_path = '/content/github_issues_cleaned.csv'\n",
        "\n",
        "# Step 0: Clear existing cleaned file if it exists\n",
        "if os.path.exists(cleaned_csv_path):\n",
        "    os.remove(cleaned_csv_path)\n",
        "\n",
        "# Step 1: Clean CSV using pandas with sampling (RAM-friendly)\n",
        "print(\"===== Strict Pandas Cleaning with Sampling =====\")\n",
        "chunksize = 100000\n",
        "expected_columns = 3\n",
        "max_chunks = 10  # Process only first 10 chunks\n",
        "rows_per_chunk = 5000  # Sample size per chunk\n",
        "\n",
        "with pd.read_csv(\n",
        "    csv_path,\n",
        "    chunksize=chunksize,\n",
        "    encoding='utf-8',\n",
        "    engine='python',\n",
        "    on_bad_lines='skip',\n",
        "    quoting=1,  # QUOTE_ALL\n",
        "    skip_blank_lines=True\n",
        ") as reader:\n",
        "    for i, chunk in enumerate(reader):\n",
        "        chunk.dropna(axis=0, how='any', inplace=True)\n",
        "        if len(chunk.columns) > expected_columns:\n",
        "            chunk = chunk.iloc[:, :expected_columns]\n",
        "        chunk_sample = chunk.sample(min(rows_per_chunk, len(chunk)))\n",
        "        chunk_sample.to_csv(cleaned_csv_path, mode='a', index=False, header=(i == 0))\n",
        "        print(f\"Strictly cleaned and sampled chunk {i + 1}\")\n",
        "        if i + 1 >= max_chunks:\n",
        "            break\n",
        "\n",
        "# Step 2: Monitor system performance\n",
        "monitoring = True\n",
        "performance_logs = []\n",
        "\n",
        "def monitor_performance(log_list, interval=0.5):\n",
        "    proc = psutil.Process()\n",
        "    while monitoring:\n",
        "        mem = proc.memory_info().rss / (1024 * 1024)\n",
        "        cpu = proc.cpu_percent(interval=None)\n",
        "        log_list.append((time.time(), mem, cpu))\n",
        "        time.sleep(interval)\n",
        "\n",
        "monitor_thread = threading.Thread(target=monitor_performance, args=(performance_logs,))\n",
        "monitor_thread.start()\n",
        "\n",
        "start_time = time.time()\n",
        "print(\"===== PyArrow Processing Started =====\")\n",
        "\n",
        "# Step 3: Load with PyArrow\n",
        "read_options = pv.ReadOptions(use_threads=True, block_size=5_000_000)\n",
        "parse_options = pv.ParseOptions(\n",
        "    delimiter=',',\n",
        "    quote_char='\"',\n",
        "    newlines_in_values=True,\n",
        "    invalid_row_handler=lambda row: 'skip'\n",
        ")\n",
        "convert_options = pv.ConvertOptions(strings_can_be_null=True)\n",
        "\n",
        "table = pv.read_csv(\n",
        "    cleaned_csv_path,\n",
        "    read_options=read_options,\n",
        "    parse_options=parse_options,\n",
        "    convert_options=convert_options\n",
        ")\n",
        "\n",
        "print(f\"Loaded {table.num_rows} records.\")\n",
        "\n",
        "# Step 4: Clean using PyArrow\n",
        "for col in ['issue_title', 'body']:\n",
        "    if col in table.column_names:\n",
        "        table = table.set_column(\n",
        "            table.schema.get_field_index(col),\n",
        "            col,\n",
        "            pc.utf8_trim(\n",
        "                pc.fill_null(table[col], 'No Title' if col == 'issue_title' else ''),\n",
        "                options=pc.TrimOptions(characters=' ')\n",
        "            )\n",
        "        )\n",
        "\n",
        "# Step 5: Convert to Pandas and drop duplicates\n",
        "df = table.to_pandas()\n",
        "initial_len = len(df)\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Removed {initial_len - len(df)} duplicate rows.\")\n",
        "\n",
        "# Step 6: (Optional) Convert back to PyArrow table\n",
        "table = pa.Table.from_pandas(df)\n",
        "\n",
        "monitoring = False\n",
        "monitor_thread.join()\n",
        "end_time = time.time()\n",
        "\n",
        "# Step 7: Performance summary\n",
        "total_time = end_time - start_time\n",
        "num_records = table.num_rows\n",
        "throughput = num_records / total_time\n",
        "peak_mem = max(m for _, m, _ in performance_logs)\n",
        "avg_mem = sum(m for _, m, _ in performance_logs) / len(performance_logs)\n",
        "peak_cpu = max(c for _, _, c in performance_logs)\n",
        "avg_cpu = sum(c for _, _, c in performance_logs) / len(performance_logs)\n",
        "\n",
        "print(\"\\n===== PyArrow Performance Summary =====\")\n",
        "print(f\"Execution time: {total_time:.2f} seconds\")\n",
        "print(f\"Records processed: {num_records}\")\n",
        "print(f\"Throughput: {throughput:.2f} records/second\")\n",
        "print(f\"Average memory usage: {avg_mem:.2f} MB\")\n",
        "print(f\"Peak memory usage: {peak_mem:.2f} MB\")\n",
        "print(f\"Average CPU usage: {avg_cpu:.2f}%\")\n",
        "print(f\"Peak CPU usage: {peak_cpu:.2f}%\")\n",
        "print(\"Ease of Processing: Fast, memory-efficient, with seamless Pandas integration.\")\n",
        "print(\"======================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZEoL3rUrWIi",
        "outputId": "74dfa54a-4ad8-4268-eb34-786014b9d416"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Strict Pandas Cleaning with Sampling =====\n",
            "Strictly cleaned and sampled chunk 1\n",
            "Strictly cleaned and sampled chunk 2\n",
            "Strictly cleaned and sampled chunk 3\n",
            "Strictly cleaned and sampled chunk 4\n",
            "Strictly cleaned and sampled chunk 5\n",
            "Strictly cleaned and sampled chunk 6\n",
            "Strictly cleaned and sampled chunk 7\n",
            "Strictly cleaned and sampled chunk 8\n",
            "Strictly cleaned and sampled chunk 9\n",
            "Strictly cleaned and sampled chunk 10\n",
            "===== PyArrow Processing Started =====\n",
            "Loaded 50000 records.\n",
            "Removed 2 duplicate rows.\n",
            "\n",
            "===== PyArrow Performance Summary =====\n",
            "Execution time: 1.68 seconds\n",
            "Records processed: 49998\n",
            "Throughput: 29707.18 records/second\n",
            "Average memory usage: 4858.99 MB\n",
            "Peak memory usage: 5846.79 MB\n",
            "Average CPU usage: 63.10%\n",
            "Peak CPU usage: 96.10%\n",
            "Ease of Processing: Fast, memory-efficient, with seamless Pandas integration.\n",
            "======================================\n"
          ]
        }
      ]
    }
  ]
}