<h1 align="center"> 
  SwiftParse - Big Data Analysis of 2019 Airline Delays with Weather & Airport Detail
  <br>
</h1>

<table border="solid" align="center">
  <tr>
    <th>Name</th>
    <th>Matric Number</th>
  </tr>
  <tr>
    <td width=80%>WAN NUR SOFEA BINTI MOHD HASBULLAH</td>
    <td>A22EC0115</td>
  </tr>
  <tr>
    <td width=80%>LOW YING XI</td>
    <td>A22EC0187</td>
  </tr>
</table>

In this assignment, we explored practical techniques for handling large-scale datasets efficiently using Python. Our focus was on applying five big data strategies—loading less data, chunking, optimizing data types, sampling, and parallel processing with Dask—to a real-world airline delay dataset exceeding 700MB. We evaluated each strategy’s performance in terms of memory usage and execution time. Additionally, we compared three popular data processing libraries—Pandas, Dask, and Polars—by performing the same delay rate analysis across all three, allowing us to benchmark their efficiency and scalability in processing and cleaning large datasets.

<table border="solid" align="center">
  <tr>
    <th>File Name</th>
    <th>Explanation</th>
    <th>Link</th>
  </tr>
  <tr>
    <th>big_data.md</th>
    <th>Explanation on big_data.md</th>
    <th>link</th>
  </tr>
    <tr>
    <th>big_data.pynb</th>
    <th>Explanation on big_data.pynb</th>
    <th>link</th>
  </tr>  <tr>
    <th>kaggle.json</th>
    <th>Explanation on kaggle.json</th>
    <th>link</th>
  </tr>
</table>
